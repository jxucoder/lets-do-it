author,author_mail,author_time,filename,comment
Rong Rong,rongr@fb.com,2020-09-08 17:08:00,.circleci/cimodel/data/binary_build_definitions.py,# TODO cuda images should consolidate into tag-base images similar to rocm
Edward Yang,ezyang@fb.com,2019-06-04 07:21:19,.circleci/cimodel/data/pytorch_build_definitions.py,# TODO expand this to cover all the USE_* that we want to test for
Karl Ostmo,kostmo@gmail.com,2019-02-22 20:10:22,.circleci/cimodel/pytorch_build_definitions.py,# TODO: Eliminate the special casing for docker paths
Karl Ostmo,kostmo@gmail.com,2019-02-22 20:10:22,.circleci/cimodel/pytorch_build_definitions.py,"# TODO When merging the caffe2 and pytorch jobs, it might be convenient for a while to make a"
Karl Ostmo,kostmo@gmail.com,2019-02-22 11:22:14,.circleci/cimodel/pytorch_build_definitions.py,# TODO This is a hack to special case some configs just for the workflow list
Jiakai Liu,liujiakai@fb.com,2019-04-08 16:19:51,.circleci/cimodel/data/pytorch_build_definitions.py,# TODO: do we need clang to compile host binaries like protoc?
Rong Rong,rongr@fb.com,2020-09-01 10:16:46,.circleci/cimodel/data/pytorch_build_definitions.py,# TODO: fix pure_torch python test packaging issue.
Karl Ostmo,kostmo@gmail.com,2019-02-22 20:10:22,.circleci/cimodel/pytorch_build_definitions.py,# TODO why does this not have a test?
Karl Ostmo,kostmo@gmail.com,2019-02-22 11:22:14,.circleci/cimodel/pytorch_build_definitions.py,# TODO convert to recursion
Karl Ostmo,kostmo@gmail.com,2020-05-18 13:32:12,.circleci/cimodel/data/simple/binary_smoketest.py,TODO: Refactor circleci/cimodel/data/binary_build_data.py to generate this file
Karl Ostmo,kostmo@gmail.com,2020-05-18 13:32:12,.circleci/cimodel/data/simple/binary_smoketest.py,TODO
Nikita Shulga,nshulga@fb.com,2022-01-18 11:30:40,.github/scripts/gitutils.py,# TODO: Handle merge commits correctly
Jiakai Liu,liujiakai@fb.com,2020-07-02 21:06:30,android/test_app/make_assets_custom.py,# TODO: create script model with `torch.jit.script`
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,aten/src/ATen/nnapi/codegen.py,// TODO: Maybe add better logging here.
Bo Wang,bowangbj@fb.com,2021-07-15 12:51:07,benchmarks/distributed/ddp/compare/compare_ddp.py,# TODO(bowangbj): Switch to real training set from ImageNet.
Garrett Cramer,gcramer@fb.com,2021-07-14 13:14:08,benchmarks/distributed/rpc/parameter_server/launcher.py,rpc_backend_options (rpc): configurations/options for the rpc TODO: fix
Wanchao Liang,wanchaol@users.noreply.github.com,2019-03-27 14:39:33,benchmarks/fastrnns/bench.py,# TODO: Maybe add a separate section for the layernorm/dropout lstms
Wanchao Liang,wanchaol@users.noreply.github.com,2019-03-27 14:39:33,benchmarks/fastrnns/profile.py,"internal_run=True,  # Unused, get rid of this TODO"
albanD,desmaison.alban@gmail.com,2020-08-24 13:25:00,benchmarks/functional_autograd_benchmark/torchvision_models.py,# TODO (alband) Why this is not automatically broadcasted? (had to add the repeat)
albanD,desmaison.alban@gmail.com,2020-08-24 13:25:00,benchmarks/functional_autograd_benchmark/torchvision_models.py,"# TODO this should probably be a separate loss, not hacked in this one here"
albanD,desmaison.alban@gmail.com,2020-08-24 13:25:00,benchmarks/functional_autograd_benchmark/torchvision_models.py,# TODO use valid to mask invalid areas due to padding in loss
Taylor Robie,taylorrobie@fb.com,2021-04-14 17:51:54,benchmarks/instruction_counts/applications/ci.py,# TODO: Annotate with TypedDict when 3.8 is the minimum supported verson.
Taylor Robie,taylorrobie@fb.com,2021-04-05 11:15:47,benchmarks/instruction_counts/definitions/standard.py,# TODO: LSTM can't be TorchScript'd
Mingzhe Li,mingzhe0908@fb.com,2019-10-28 11:08:46,benchmarks/operator_benchmark/benchmark_caffe2.py,TODO(mingzhe0908): introduce device and add it to the benchmark name
Mingzhe Li,mingzhe0908@fb.com,2019-11-08 22:02:53,benchmarks/operator_benchmark/benchmark_core.py,# TODO(mingzhe09088): remove this deepcopy when we encounter
Mingzhe Li,mingzhe0908@fb.com,2019-04-02 17:03:23,benchmarks/operator_benchmark/benchmark_core.py,# TODO: consider time-bound constraints as well.
Mingzhe Li,mingzhe0908@fb.com,2019-05-31 09:08:09,benchmarks/operator_benchmark/benchmark_core.py,# TODO: consider regex matching for test filtering.
Mingzhe Li,mingzhe0908@fb.com,2019-10-14 15:41:58,benchmarks/operator_benchmark/benchmark_pytorch.py,""""""" TODO (mingzhe): it is not necessary to sum up everything by myself,"
Mingzhe Li,mingzhe0908@fb.com,2019-06-03 14:51:58,benchmarks/operator_benchmark/benchmark_pytorch.py,# TODO: can we use JIT here to reduce python overhead?
Mingzhe Li,mingzhe0908@fb.com,2019-04-02 17:03:23,benchmarks/operator_benchmark/benchmark_utils.py,# TODO: consider more complex/custom dynamic ranges for
Mingzhe Li,mingzhe0908@fb.com,2019-11-11 16:54:46,benchmarks/operator_benchmark/benchmark_utils.py,# TODO(mingzhe0908) remove the conversion to list.
Mingzhe Li,mingzhe0908@fb.com,2019-11-11 16:54:46,benchmarks/operator_benchmark/benchmark_utils.py,# TODO(mingzhe0908):
Mingzhe Li,mingzhe0908@fb.com,2019-11-11 16:54:46,benchmarks/operator_benchmark/benchmark_utils.py,# TODO(mingzhe09088): cache the results to avoid recalculation overhead
Mingzhe Li,mingzhe0908@fb.com,2019-11-11 16:54:46,benchmarks/operator_benchmark/benchmark_utils.py,TODO (mingzhe09088):
Sam Estep,sestep@fb.com,2021-03-05 17:19:22,benchmarks/operator_benchmark/common/tests/jit_forward_test.py,# TODO(mingzhe): use one forward method for both JIT and Eager
Mingzhe Li,mingzhe0908@fb.com,2019-05-31 09:08:09,benchmarks/operator_benchmark/operator_benchmark.py,# TODO (mingzhe09088): get rid of noqa
Zafar Takhirov,cc.rafaz@zafar.cc,2019-11-11 13:28:25,benchmarks/operator_benchmark/pt/qarithmetic_test.py,"# contig=(False, True),  # TODO: Reenable this after #29435"
Zafar Takhirov,cc.rafaz@zafar.cc,2019-11-09 14:18:44,benchmarks/operator_benchmark/pt/qarithmetic_test.py,# TODO: Consider more diverse shapes
Zafar Takhirov,cc.rafaz@zafar.cc,2019-11-09 14:19:25,benchmarks/operator_benchmark/pt/qcomparators_test.py,# TODO: Consider more diverse shapes
Zafar Takhirov,cc.rafaz@zafar.cc,2019-11-12 11:16:35,benchmarks/operator_benchmark/pt/qinterpolate_test.py,"'contig': [True],  # TODO: Add `False` after #29435"
Ben Koopman,bkoopman@fb.com,2021-09-27 16:00:13,benchmarks/operator_benchmark/pt/quantization_test.py,"# TODO(future PR) Combine config for floating point zero_point with other configs, once it is"
Zafar Takhirov,cc.rafaz@zafar.cc,2019-11-11 23:46:58,benchmarks/operator_benchmark/pt/qunary_test.py,# TODO: Uncomment the ops whenever they are implemented for quantized tensor.
Mikhail Zolotukhin,mvz@fb.com,2020-03-20 11:38:35,benchmarks/tensorexpr/__main__.py,# TODO: make sure virtual devices such as 'cpu1' and 'cpu4' are supported.
Xiaoqiang Zheng,zhengxq@gmail.com,2021-01-21 09:46:14,benchmarks/tensorexpr/__main__.py,# TODO: output dtype in the config and  parse it back from the str
Mikhail Zolotukhin,mvz@fb.com,2020-03-20 11:38:35,benchmarks/tensorexpr/broadcast.py,# TODO: merge this with elementwise bench
Yinghai Lu,elvis.lu@gmail.com,2020-04-17 20:53:28,caffe2/contrib/fakelowp/test/test_batchnorm_nnpi_fp16.py,"# TODO: using hypothesis seed, sweep dimensions"
Venkata Chintapalli,venkatach@fb.com,2020-07-28 16:00:23,caffe2/contrib/fakelowp/test/test_deq_swish_quant_nnpi.py,# TODO: add an assertion to check the optimized net
Hector Yuen,hyz@fb.com,2020-08-12 09:28:43,caffe2/contrib/fakelowp/test/test_int8_ops_nnpi.py,"f=st.integers(1, 1),  # TODO: figure a safe number to increase"
Hector Yuen,hyz@fb.com,2020-07-07 19:42:58,caffe2/contrib/fakelowp/test/test_op_nnpi_fp16.py,# TODO: move atol to 1e-8 once we get a non-lowered swish implementation
Di Yu,diyu@mail.usf.edu,2018-02-27 12:27:41,caffe2/contrib/playground/resnet50demo/explicit_resnet_forward.py,"# TODO: This can be further optimized by passing dim_in, dim_out = features,"
Pieter Noordhuis,pietern@fb.com,2017-05-17 14:32:56,caffe2/experiments/python/SparseTransformer.py,# TODO(wyiming): check whether it is correct here
Pieter Noordhuis,pietern@fb.com,2017-05-17 14:32:56,caffe2/experiments/python/SparseTransformer.py,# TODO(wyiming): create a new Op here
Pieter Noordhuis,pietern@fb.com,2017-05-17 14:32:56,caffe2/experiments/python/SparseTransformer.py,# TODO: write a non-layer checker and log it
Pieter Noordhuis,pietern@fb.com,2017-05-17 14:32:56,caffe2/experiments/python/convnet_benchmarks.py,"(NOTE: Numbers below prior with missing parameter=update step, TODO to update)"
Pieter Noordhuis,pietern@fb.com,2017-05-17 14:32:56,caffe2/experiments/python/net_construct_bench.py,# TODO: use argv
Jerry Zhang,jerryzh@fb.com,2018-09-05 16:13:54,caffe2/python/__init__.py,# TODO: refactor & remove the following alias
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/caffe_translator.py,"# TODO(jiayq): if we have a protobuf that uses this, lift this constraint"
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/caffe_translator.py,# TODO(jiayq): find a protobuf that uses this and verify.
Yiming Wu,wyiming@fb.com,2017-04-25 15:59:13,caffe2/python/cnn.py,# TODO(wyiming): remove this dummy helper later
Ilia Cherniavskii,iliacher@fb.com,2017-09-18 16:06:41,caffe2/python/control_ops_grad.py,# TODO(iliacher): Remove unnecessary blob copying
Junjie Bai,bai@in.tum.de,2019-02-20 21:05:59,caffe2/python/convnet_benchmarks_test.py,# TODO: investigate why this randomly core dump in ROCM CI
Aapo Kyrola,akyrola@fb.com,2017-05-30 11:54:51,caffe2/python/core.py,"# TODO: T18892922, use device annotations"
Yangqing Jia,jiayq84@gmail.com,2016-05-13 14:43:48,caffe2/python/core.py,# TODO(jiayq): enforce using BlobReference instead of raw strings.
Martin Raison,raison@fb.com,2016-12-01 01:13:20,caffe2/python/core.py,# TODO not sure what this message really means
Yangqing Jia,jiayq84@gmail.com,2016-09-06 15:54:56,caffe2/python/core.py,# TODO(tulloch) - Propagate GradientWrapper up through the stack.
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/core.py,# TODO(azzolini): improve schema type checking
Aapo Kyrola,akyrola@fb.com,2017-07-27 13:08:37,caffe2/python/data_parallel_model.py,# TODO: make into assert
Ahmed Taei,ataei@fb.com,2017-05-15 18:02:16,caffe2/python/data_parallel_model.py,# TODO(ataei) : Stop building the graph here to get model average ?
Aapo Kyrola,akyrola@fb.com,2017-09-15 16:05:58,caffe2/python/data_parallel_model.py,"# TODO: for _shared_model, do only NCCLReduce"
Aapo Kyrola,akyrola@fb.com,2017-09-06 23:54:20,caffe2/python/data_parallel_model.py,"# Special tree reduction for 16 gpus, TODO generalize like in muji.py"
Aapo Kyrola,akyrola@fb.com,2017-09-15 16:05:58,caffe2/python/data_parallel_model.py,"# TODO: for _shared_model, no need to broadcast"
Yangqing Jia,jiayq84@gmail.com,2016-07-28 15:06:04,caffe2/python/dataset.py,TODO: fixme
Abhinav Jauhri,abhinavj@fb.com,2019-05-23 20:34:48,caffe2/python/examples/imagenet_trainer.py,TODO: add checkpointing here.
Abhinav Jauhri,abhinavj@fb.com,2019-05-23 20:34:48,caffe2/python/examples/imagenet_trainer.py,# TODO: add loading from checkpoint
Abhinav Jauhri,abhinavj@fb.com,2019-05-23 20:34:48,caffe2/python/examples/imagenet_trainer.py,# TODO: add checkpointing
Brian Wignall,brianwignall@gmail.com,2020-01-17 16:01:29,caffe2/python/examples/imagenet_trainer.py,# TODO: merge with multi-precision optimizer
Abhinav Jauhri,abhinavj@fb.com,2019-05-23 20:34:48,caffe2/python/examples/imagenet_trainer.py,# TODO: use argv
Yangqing Jia,jiayq@fb.com,2016-12-15 19:53:51,caffe2/python/gradient_check_test.py,"# TODO(jiayq): as more and more tests are moving to hypothesis test, we"
Yangqing Jia,jiayq84@gmail.com,2016-05-13 14:43:48,caffe2/python/gradient_checker.py,# TODO(jiayq): use the gradient registration instead of the old
Yangqing Jia,jiayq84@gmail.com,2016-07-21 10:16:42,caffe2/python/hypothesis_test.py,# TODO(jiayq): enable gradient test when implemented.
Aapo Kyrola,akyrola@fb.com,2017-04-05 14:05:12,caffe2/python/hypothesis_test.py,"rnn_mode=st.sampled_from([""lstm""]),   # TODO: ""gru"""
Yangqing Jia,jiayq84@gmail.com,2016-09-06 15:54:56,caffe2/python/hypothesis_test.py,# TODO: name scope external inputs and outputs
Yangqing Jia,jiayq84@gmail.com,2016-09-06 15:54:56,caffe2/python/hypothesis_test.py,"# TODO(jiayq): when there are backward and GPU implementations, enable"
Yinghai Lu,yinghai@fb.com,2018-07-09 11:53:52,caffe2/python/ideep/spatial_bn_op_test.py,# TODO: It looks like IDEEP spatial_bn op outputs save_var (output[4])
Liang Xiong,lxiong@fb.com,2017-11-21 17:49:34,caffe2/python/layer_model_helper.py,''' TODO(amalevich): more documnetation on input args
Yinghai Lu,yinghai@fb.com,2018-04-10 21:11:43,caffe2/python/layer_model_helper.py,# TODO(xlwang): it's hack!
Andrey Malevich,amalevich@fb.com,2017-01-22 19:18:11,caffe2/python/layer_model_helper.py,# TODO: make GivenTensor generic
Yan Shang,yanshang@fb.com,2018-01-08 12:58:21,caffe2/python/layer_model_helper.py,# TODO:
Andrey Malevich,amalevich@fb.com,2017-02-27 23:22:06,caffe2/python/layer_model_helper.py,# TODO(amalevich): Add add support for ifbpy inline documentation
Xiaolong Wang,xlwang@fb.com,2018-03-26 11:17:27,caffe2/python/layer_model_helper.py,# TODO(xlwang): Desginated layer shadows the usage of an op as a
Andrey Malevich,amalevich@fb.com,2017-02-27 23:22:06,caffe2/python/layer_model_helper.py,# TODO(amalevich): Switch to net.operator as soon as it gets
Xiaolong Wang,xlwang@fb.com,2018-01-26 17:27:50,caffe2/python/layer_model_helper.py,# TODO(xlwang): provide more rich feature information in breakdown_map;
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/layers/sparse_to_dense.py,# TODO(amalevich): This schema is producing ranges. And thus if there is
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/layers/sparse_to_dense.py,"# TODO(amalevich): Consider moving this data to schema, instead"
Kittipat Virochsiri,kittipat@fb.com,2017-04-03 16:50:35,caffe2/python/layers/sparse_to_dense.py,# TODO: merge this to the case above?
Andrey Malevich,amalevich@fb.com,2017-02-27 23:22:06,caffe2/python/layers/functional.py,# TODO(amalevich): Move it to some shared library
Kittipat Virochsiri,kittipat@fb.com,2017-04-13 14:45:49,caffe2/python/layers/gather_record.py,# TODO(kittipat): This is a hacky solution until LengthsSum for int
Xiaolong Wang,xlwang@fb.com,2018-03-19 21:42:56,caffe2/python/layers/homotopy_weight.py,# TODO: currently model building does not have access to iter counter or
Wael Abdelghani,wael@fb.com,2017-06-05 16:52:15,caffe2/python/layers/layers.py,"# TODO(amalevich): Either return back to lambdas, that add"
Wael Abdelghani,wael@fb.com,2017-06-05 16:52:15,caffe2/python/layers/layers.py,# TODO(xlwang) init_net._net.op has type google.protobuf.\
Lin Jiang,linjiang@fb.com,2019-10-08 20:20:10,caffe2/python/layers/sparse_lookup.py,# TODO: create a new type of reducer with external weights to wrap
Dmytro Dzhulgakov,dzhulgakov@fb.com,2018-03-05 19:56:07,caffe2/python/layers/sparse_lookup.py,# TODO(amalevich): Layer should not be responsible for decision about
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/layers/tags.py,"# TODO(amalevich): Tags might need to live in their own contexts, add this"
Kittipat Virochsiri,kittipat@fb.com,2017-05-02 17:22:16,caffe2/python/layers_test.py,# TODO: TRAIN_ONLY layers are also generated in eval
Aapo Kyrola,akyrola@fb.com,2017-01-09 19:39:09,caffe2/python/memonger.py,# TODO: something smarter
Yangqing Jia,jiayq84@gmail.com,2017-09-21 15:58:12,caffe2/python/memonger.py,# TODO(tulloch): are there cases with multiple predecessors?
Aapo Kyrola,akyrola@fb.com,2017-06-14 22:31:04,caffe2/python/model_helper.py,"# TODO: when standard argument type for ""nets"" is introduced,"
Andrey Malevich,amalevich@fb.com,2017-06-02 18:09:29,caffe2/python/modeling/initializers.py,# TODO(amalevich): Add operator that will check param in the workspace
Bram Wasti,bwasti@fb.com,2017-02-22 12:33:18,caffe2/python/models/__sym_init__.py,# TODO(bwasti): A more robust handler for pathnames.
Yury Zemlyanskiy,urikz@fb.com,2017-04-27 13:17:42,caffe2/python/models/seq2seq/beam_search.py,# TODO: make attentions a generic state
Yinghai Lu,yinghai@fb.com,2018-02-20 13:56:52,caffe2/python/onnx/backend.py,# TODO: Move this into ONNX main library
James Reed,jamesreed@fb.com,2018-04-25 15:44:00,caffe2/python/onnx/backend.py,# TODO: this doesn't work with RNN ops
Yinghai Lu,yinghai@fb.com,2018-02-20 13:56:52,caffe2/python/onnx/backend.py,# TODO: Move this into ONNX main library
James Reed,jamesreed@fb.com,2018-03-29 19:18:58,caffe2/python/onnx/backend.py,# TODO: make this more efficient
Yinghai Lu,yinghai@fb.com,2018-02-20 13:56:52,caffe2/python/onnx/backend.py,# TODO: This method needs a refactor for clarity
Lu Fang,lufang@fb.com,2018-07-09 20:59:31,caffe2/python/onnx/backend.py,"# TODO: should have an unspported list of operators, be optimistic for now"
bddppq,bai@in.tum.de,2018-03-16 16:32:35,caffe2/python/onnx/tests/conversion_test.py,# TODO investigate why this is failing after changing Reshape
Jongsoo Park,jongsoo@fb.com,2018-11-03 11:56:56,caffe2/python/operator_test/conv_test.py,# TODO: Group conv in NHWC not implemented for GPU yet.
Jongsoo Park,jongsoo@fb.com,2018-11-03 11:56:56,caffe2/python/operator_test/conv_test.py,# TODO: Group conv in NHWC not implemented for GPU yet.
Jongsoo Park,jongsoo@fb.com,2019-01-03 09:43:46,caffe2/python/operator_test/conv_test.py,# TODO: Group conv in NHWC not implemented for GPU yet.
Jongsoo Park,jongsoo@fb.com,2019-01-03 09:43:46,caffe2/python/operator_test/conv_test.py,# TODO: Group 1D conv in NCHW not implemented for GPU yet.
Jongsoo Park,jongsoo@fb.com,2018-11-04 21:48:23,caffe2/python/operator_test/conv_test.py,# TODO: 1D conv in NHWC not implemented for GPU yet.
Johannes M Dieterich,Johannes.Dieterich@amd.com,2020-02-14 13:14:15,caffe2/python/operator_test/conv_test.py,"engine=st.sampled_from(["""", ""MIOPEN""]),  # TODO: add ""CUDNN"""
Jongsoo Park,jongsoo@fb.com,2018-11-04 21:48:23,caffe2/python/operator_test/conv_test.py,# TODO: 3D conv in NHWC not implemented for GPU yet.
Xiaomeng Yang,yangxm@fb.com,2019-04-04 11:46:37,caffe2/python/operator_test/conv_transpose_test.py,# TODO: Group conv_transpose in NHWC not implemented for GPU yet.
Yangqing Jia,jiayq84@gmail.com,2016-09-06 15:54:56,caffe2/python/operator_test/cross_entropy_ops_test.py,"# TODO(surya) Once CrossEntropyOp is ported to GPU, add the respective"
Simon Layton,slayton58@gmail.com,2017-06-15 22:34:59,caffe2/python/operator_test/dropout_op_test.py,# TODO(lukeyeager): enable this path when the GPU path is fixed
Simon Layton,slayton58@gmail.com,2017-06-15 22:34:59,caffe2/python/operator_test/dropout_op_test.py,# TODO(lukeyeager): enable this path when the op is fixed
Yangqing Jia,jiayq84@gmail.com,2016-09-06 15:54:56,caffe2/python/operator_test/elementwise_op_broadcast_test.py,# TODO(jiayq): make them hypothesis tests for better coverage.
Junjie Bai,bai@in.tum.de,2018-10-24 17:01:26,caffe2/python/operator_test/group_conv_test.py,# TODO: Group conv in NHWC not implemented for GPU yet.
Ahmed Taei,ataei@fb.com,2016-12-16 10:53:54,caffe2/python/operator_test/hsm_test.py,# TODO : convert to both cpu and gpu test when ready.
Romain Cledat,romainc@fb.com,2017-05-10 17:33:21,caffe2/python/operator_test/image_input_op_test.py,# TODO: This test does not test scaling because
Romain Cledat,romainc@fb.com,2017-05-10 17:33:21,caffe2/python/operator_test/image_input_op_test.py,"# TODO: To ensure that we never need to scale, we"
Kevin Wilfong,kevinwilfong@fb.com,2017-08-01 14:19:12,caffe2/python/operator_test/image_input_op_test.py,# TODO: Does not test on GPU and does not test use_gpu_transform
James Reed,jamesreed@fb.com,2017-12-05 10:16:00,caffe2/python/operator_test/matmul_op_test.py,# TODO: test trans_a and trans_b
James Reed,jamesreed@fb.com,2017-12-05 10:16:00,caffe2/python/operator_test/matmul_op_test.py,# TODO: test trans_a and trans_b
James Reed,jamesreed@fb.com,2017-12-05 10:16:00,caffe2/python/operator_test/matmul_op_test.py,# TODO: test trans_a and trans_b
James Cross,jcross@fb.com,2017-06-25 17:14:21,caffe2/python/operator_test/rnn_cell_test.py,# layers than previous test. TODO: investigate why.
Hector Yuen,hyz@fb.com,2018-10-12 13:56:04,caffe2/python/operator_test/shape_inference_test.py,# TODO: find a tighter bound
Hector Yuen,hyz@fb.com,2020-01-08 16:54:33,caffe2/python/operator_test/shape_inference_test.py,# TODO: find a tighter bound
Hector Yuen,hyz@fb.com,2018-10-12 13:56:04,caffe2/python/operator_test/shape_inference_test.py,# TODO: find a tighter bound
Hector Yuen,hyz@fb.com,2020-01-08 16:54:33,caffe2/python/operator_test/shape_inference_test.py,# TODO: find a tighter bound
Pooya Davoodi,pdavoodi@nvidia.com,2017-05-03 13:30:45,caffe2/python/operator_test/sparse_ops_test.py,# TODO(dzhulgakov): add test cases for failure scenarios
Xiaolong Wang,xlwang@fb.com,2017-05-09 13:14:07,caffe2/python/optimizer.py,"# TODO(xlwang): In transfer learning, parameter initialized from pretrained"
Qinqing Zheng,enosair@users.noreply.github.com,2018-02-25 14:58:31,caffe2/python/optimizer.py,# TODO(zqq): support LARS for sparse parameters
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/pipeline.py,TODO(azzolini): simplify once all processors use NetBuilder API.
Kevin Chen,kchen357@fb.com,2019-10-03 09:37:42,caffe2/python/regularizer.py,"# TODO: the second dim (num of input nodes) of param is after feature preproc,"
Kevin Chen,kchen357@fb.com,2019-10-11 11:22:53,caffe2/python/regularizer.py,"# TODO: the second dim (num of input nodes) of param is after feature preproc,"
Orion Reblitz-Richardson,orionr@gmail.com,2018-06-26 14:55:48,caffe2/python/regularizer.py,# TODO(xlwang): param might still be negative at the initialization time or
Anders Papitto,anderspapitto@gmail.com,2018-02-05 20:26:31,caffe2/python/rnn_cell.py,"# TODO If this codepath becomes popular, it may be worth"
James Cross,jcross@fb.com,2017-05-03 10:02:00,caffe2/python/rnn_cell.py,"'bidirectional': 0,  # TODO"
James Cross,jcross@fb.com,2017-05-03 10:02:00,caffe2/python/rnn_cell.py,"'dropout': 1.0,  # TODO"
James Cross,jcross@fb.com,2017-05-03 10:02:00,caffe2/python/rnn_cell.py,"'input_mode': 'linear',  # TODO"
James Cross,jcross@fb.com,2017-05-03 10:02:00,caffe2/python/rnn_cell.py,"seed=random.randint(0, 100000),  # TODO: dropout seed"
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/schema.py,# TODO(azzolini): figure out better way of representing this
Yangqing Jia,jiayq84@gmail.com,2016-08-10 11:02:15,caffe2/python/schema.py,# TODO(dzhulgakov): tweak this to make it work with PackedStruct
Yangqing Jia,jiayq84@gmail.com,2016-08-10 11:02:15,caffe2/python/schema.py,# TODO: check schema
Yangqing Jia,jiayq84@gmail.com,2016-11-14 14:58:04,caffe2/python/schema.py,# TODO add more checks
Alisson Gusatti Azzolini,azzolini@fb.com,2017-01-30 11:22:41,caffe2/python/task.py,# TODO(azzolini): consistency checks
Alisson Gusatti Azzolini,azzolini@fb.com,2017-02-21 20:42:35,caffe2/python/task.py,TODO(azzolini): make this schema-based.
Yinghai Lu,yinghai@fb.com,2018-04-11 17:03:54,caffe2/python/trt/test_trt.py,# TODO: This is copied from https://github.com/onnx/onnx/blob/master/onnx/backend/test/runner/__init__.py. Maybe we should
Yangqing Jia,jiayq84@gmail.com,2016-08-10 11:02:15,caffe2/python/tt_core.py,# TODO(Surya) Write a method to convert an entire network where all fully
Davin Wang,davin.wang@live.com,2017-07-26 11:17:19,caffe2/python/utils.py,"# TODO: complete the data type: bool, float16, byte, int64, string"
Fan Wang,fanwang@fb.com,2019-12-26 16:38:11,caffe2/python/utils.py,"# TODO: complete the data type: bool, float16, byte, string"
Yangqing Jia,jiayq84@gmail.com,2016-07-21 10:16:42,caffe2/python/workspace.py,TODO(Yangqing): this does not work well under ipython yet. According to
Yangqing Jia,jiayq84@gmail.com,2016-10-07 13:08:53,caffe2/python/workspace.py,# TODO(jiayq): refactor core.py/workspace.py to avoid circular deps
Kittipat Virochsiri,kittipat@fb.com,2018-07-20 14:49:16,caffe2/python/workspace.py,# TODO(jiayq): refactor core.py/workspace.py to avoid circular deps
Dmytro Dzhulgakov,dzhulgakov@fb.com,2019-04-05 01:04:58,caffe2/python/workspace_test.py,# TODO: make caffe2 side load return python-sided module
Peter Goldsborough,psag@fb.com,2018-08-17 15:35:32,docs/cpp/conf.py,# TODO: change to [:2] at v1.0
Peter Goldsborough,psag@fb.com,2018-08-17 15:35:32,docs/cpp/conf.py,# TODO: verify this works as expected
mattip,matti.picus@gmail.com,2020-06-04 10:47:43,docs/source/conf.py,# TODO: document these and remove them from here.
Eli Stevens,wickedgrey@gmail.com,2017-02-26 05:33:26,docs/source/conf.py,# TODO: change to [:2] at v1.0
Eli Stevens,wickedgrey@gmail.com,2017-02-26 05:33:26,docs/source/conf.py,# TODO: verify this works as expected
bddppq,bai@in.tum.de,2018-04-02 11:06:29,scripts/model_zoo/update-caffe2-models.py,# TODO currently onnx can't translate squeezenet :(
bddppq,bai@in.tum.de,2018-04-02 11:06:29,scripts/model_zoo/update-caffe2-models.py,"# TODO currently vgg19 doesn't work in the CI environment,"
bddppq,bai@in.tum.de,2018-04-02 11:06:29,scripts/model_zoo/update-models-from-caffe2.py,# TODO: Add GPU support
peter,peterghost86@gmail.com,2019-11-06 09:00:52,setup.py,# TODO: Fix for python < 3.3
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,test/test_ao_sparse.py,"# TODO: Once more test files are created, move the contents to a ao folder."
Zafar,cc.rafaz@zafar.cc,2021-09-28 14:11:12,test/ao/sparsity/test_parametrization.py,# TODO: Need to find a clean way of exporting the parametrized model
Aliaksandr Ivanou,aivanou@fb.com,2021-03-22 23:13:48,test/distributed/elastic/agent/server/test/local_elastic_agent_test.py,# TODO(aivanou): t83447589 come up with the proper fix
Aliaksandr Ivanou,aivanou@fb.com,2021-03-22 23:13:48,test/distributed/elastic/agent/server/test/local_elastic_agent_test.py,# TODO(aivanou): t83447589 come up with the proper fix
Kiuk Chung,kiuk@fb.com,2021-03-10 12:25:58,test/distributed/elastic/multiprocessing/bin/test_script.py,# TODO <DELETE_ME>
Rohan Varma,rvarm1@fb.com,2021-12-01 00:14:51,test/distributed/fsdp/test_wrap.py,# TODO: test the various init modes.
Rohan Varma,rvarm1@fb.com,2021-09-25 13:24:15,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: sandcastle_skip_if does not work here.
Yu Guo,yuguo@fb.com,2021-07-15 10:01:40,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: Replace this `_broadcast_object` with `broadcast_object_list`
Andrew Gu,andgu@fb.com,2021-08-02 08:31:56,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: Add `test_ddp_with_zero_step_parity_cpu()` once the Gloo
Andrew Gu,andgu@fb.com,2021-08-02 08:31:56,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: Add `test_ddp_with_zero_step_interleaved_parity_cpu()` once the
Andrew Gu,andgu@fb.com,2021-08-13 08:19:23,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: Add `test_ddp_with_zero_step_uniform_parity_cpu()` once the Gloo
Andrew Gu,andgu@fb.com,2021-08-13 08:19:23,test/distributed/optim/test_zero_redundancy_optimizer.py,# TODO: Add `test_ddp_with_zero_step_interleaved_uniform_parity_cpu()` once
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_common.py,# TODO: investigate this test and the test is known to have issues
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Alexander Golynski,agolynski@fb.com,2021-05-11 14:45:58,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Alexander Golynski,agolynski@fb.com,2021-05-11 14:45:58,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_gloo.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Wanchao Liang,wanchaol@fb.com,2021-12-02 10:08:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Wanchao Liang,wanchaol@fb.com,2021-12-02 10:08:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Wanchao Liang,wanchaol@fb.com,2021-12-02 10:08:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Wanchao Liang,wanchaol@fb.com,2021-12-02 10:08:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Wanchao Liang,wanchaol@fb.com,2021-12-02 10:08:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Rohan Varma,rvarm1@fb.com,2021-10-14 22:22:08,test/distributed/test_c10d_nccl.py,# TODO: smaller timeout can fail since PG NCCl does health check in
Rohan Varma,rvarm1@fb.com,2021-09-08 09:17:49,test/distributed/test_c10d_nccl.py,"# TODO: We can also test that if rank 0 attempts to use the communicator,"
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO: Combine the following tests once https://github.com/pytorch/pytorch/issues/55967
Pavel Belevich,pbelevich@fb.com,2021-04-21 22:09:13,test/distributed/test_c10d_nccl.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Rohan Varma,rvarm1@fb.com,2022-01-19 10:04:31,test/distributed/test_c10d_nccl.py,# TODO: non-reentrant based checkpointing of DDP module with
Mike Ruberry,mruberry@devfair044.maas,2019-10-08 09:50:28,test/test_distributions.py,# TODO: remove this global setting
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_distributions.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_distributions.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_distributions.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_distributions.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Thomas Viehmann,tv.code@beamnet.de,2021-03-10 13:14:08,test/distributions/test_distributions.py,# TODO: gradcheck seems to mutate the sample values so that the simplex
Maruan,alshedivat@users.noreply.github.com,2018-03-21 16:32:14,test/test_distributions.py,"# TODO: Once _check_log_prob works with multidimensional distributions,"
Neeraj Pradhan,npradhan@uber.com,2019-03-19 10:18:12,test/test_distributions.py,# TODO: increase precision once imbalance on GPU is fixed.
neerajprad,neerajprad@devvm903.atn0.facebook.com,2020-10-12 10:49:51,test/test_distributions.py,# TODO: make this a pytest parameterized test
Adam Paszke,adam.paszke@gmail.com,2016-09-21 20:36:39,test/error_messages/storage.py,# TODO: frombuffer
Lu Fang,lufang@fb.com,2019-09-19 14:53:11,test/backward_compatibility/check_backward_compatibility.py,# TODO Print out more details about why candidates don't match.
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2022-01-05 23:38:45,test/forward_backward_compatibility/check_forward_backward_compatibility.py,"# TODO in case there is FC breaking changes,"
Jerry Zhang,jerryzh@fb.com,2021-10-28 23:57:19,test/fx2trt/test_quant_trt.py,# TODO: test multiple inputs setting and enable multiple inputs
Jerry Zhang,jerryzh@fb.com,2021-12-30 12:29:32,test/fx2trt/test_quant_trt.py,"# TODO: input_quantized_idxs only supports quint8, we can remove this"
Jerry Zhang,jerryzh@fb.com,2022-01-02 11:19:18,test/fx2trt/test_quant_trt.py,# TODO: change back to torch.qint8 after input_quantized_idxs and output_quantized_idxs
Jerry Zhang,jerryzh@fb.com,2022-01-02 11:19:18,test/fx2trt/test_quant_trt.py,# TODO: use self.qconfig after input_quantized_idxs and output_quantized_idxs
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_autodiff_subgraph_slicing.py,# TODO: It is better if we can test directly on graphs instead of the current
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_class_type.py,"# TODO test: interface-interface class-interface inheritance errors,"
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_class_type.py,# TODO - support compiling classes from strings in jit.CompilationUnit
John Clow,jclow@fb.com,2022-01-13 13:55:26,test/jit/test_device_analysis.py,# TODO: Delete this when PR #67786 is merged.
Jane Xu,janeyx@fb.com,2021-04-07 14:59:29,test/jit/test_enum.py,# TODO: rewrite code so that the highlight is not empty.
Jane Xu,janeyx@fb.com,2021-04-07 14:59:29,test/jit/test_enum.py,# TODO: rewrite code so that the highlight is not empty.
Zino Benaissa,zinob@fb.com,2020-06-09 19:08:10,test/jit/test_freezing.py,"# TODO:  Although there are no mutation, the alias analysis"
Zino Benaissa,zinob@fb.com,2020-09-23 11:12:56,test/jit/test_freezing.py,"# TODO:  Although there are no mutation, the alias analysis"
John Clow,jclow@fb.com,2021-10-05 20:07:01,test/jit/test_freezing.py,# TODO: merge with check_linear_optimizations once both diffs land
Lillian Johnson,lillianjohnson@fb.com,2021-01-20 09:04:11,test/jit/test_hooks.py,# TODO: add this test back once figured out how to print error msg
Lillian Johnson,lillianjohnson@fb.com,2020-10-20 16:43:25,test/jit/test_isinstance.py,# TODO: above line in eager will evaluate to True while in
Meghan Lele,meghanl@fb.com,2021-07-01 20:27:02,test/jit/test_list_dict.py,"# TODO: Something like input_list[:1] = [1, 2, 3, 4, 5]"
Rong Rong (AI Infra),rongr@fb.com,2021-04-08 14:26:38,test/jit/test_misc.py,# TODO: Add support for f-strings in string parser frontend
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_models.py,dp_ratio = 0.0  # For deterministic testing TODO: change by fixing seed in checkTrace?
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_models.py,# TODO: add future as input with default val
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_models.py,# TODO: chunk call should appear as the for loop iterable
Michael Suo,suo@fb.com,2019-11-06 13:17:23,test/jit/test_models.py,# TODO: toggle export_import once above issues are fixed
Wanchao Liang,wanchaol@fb.com,2019-11-05 11:27:53,test/jit/test_module_interface.py,# TODO: enable linting check for this file
Zafar,cc.rafaz@zafar.cc,2021-06-30 23:52:31,test/jit/test_parametrization.py,# TODO: Need to fix the scripting in parametrizations
Elias Ellison,eellison@devfair044.maas,2021-05-21 08:48:13,test/jit/test_peephole.py,assert x1 == False  # noqa: E712 TODO: canonicalize x is False to aten::eq
Elias Ellison,eellison@devfair044.maas,2021-05-21 08:48:13,test/jit/test_peephole.py,assert x1 == False  # noqa: E712 TODO: canonicalize x is False to aten::eq
Elias Ellison,eellison@devfair044.maas,2021-05-21 08:48:13,test/jit/test_peephole.py,assert x1 == False  # noqa: E712 TODO: canonicalize x is False to aten::eq
Elias Ellison,eellison@devfair044.maas,2021-05-21 08:48:13,test/jit/test_peephole.py,assert x1 == False  # noqa: E712 TODO: canonicalize x is False to aten::eq
Elias Ellison,eellison@devfair044.maas,2021-05-21 08:48:13,test/jit/test_peephole.py,assert x1 == False  # noqa: E712 TODO: canonicalize x is False to aten::eq
Michael Suo,suo@fb.com,2019-10-14 15:57:21,test/jit/test_recursive_script.py,# TODO: re-enable this once this test is in a Python 3-only syntax
Michael Suo,suo@fb.com,2019-10-14 15:57:21,test/jit/test_recursive_script.py,"# TODO: as a followup, fix this test"
Elias Ellison,eellison@devfair044.h1.fair,2021-09-07 18:19:14,test/jit/test_symbolic_shape_analysis.py,"# (True,),  TODO: https://github.com/pytorch/pytorch/issues/63405"
Elias Ellison,eellison@devfair044.h1.fair,2021-09-07 18:19:14,test/jit/test_symbolic_shape_analysis.py,"# (False,), TODO: https://github.com/pytorch/pytorch/issues/63405"
Elias Ellison,eellison@devfair044.h1.fair,2021-09-15 13:43:12,test/jit/test_symbolic_shape_analysis.py,"# TODO: merge into opinfos, having difficulties there"
Elias Ellison,eellison@devfair044.h1.fair,2021-10-20 16:09:33,test/jit/test_symbolic_shape_analysis.py,"# TODO: unify with opinfo tests, traces of lists dont preserve sizes in IR"
Wanchao Liang,wanchaol@users.noreply.github.com,2020-06-17 17:24:52,test/jit/test_tracer.py,# TODO: implement
Rong Rong,rongr@apache.org,2021-05-10 07:27:52,test/jit/test_types.py,# TODO add test to use PEP585 type annotation for return type after py3.9
Ansley Ussery,ansley@fb.com,2021-09-03 06:10:37,test/jit/test_union.py,# TODO: We would like to eventually support this. The issue is being
Ansley Ussery,ansley@fb.com,2021-09-03 06:10:37,test/jit/test_union.py,# TODO: There's currently an unrelated bug in
Ansley Ussery,ansley@fb.com,2021-09-10 16:18:33,test/jit/test_union.py,# TODO: Support mixed list comprehensions
Ansley Ussery,ansley@fb.com,2021-10-14 17:30:13,test/jit/test_union.py,# TODO(@ansley): Support mixed list comprehensions
Ansley Ussery,ansley@fb.com,2021-09-10 16:18:33,test/jit/test_union.py,# TODO: String frontend does not support tuple unpacking
Ansley Ussery,ansley@fb.com,2021-10-14 17:30:13,test/jit/test_union.py,# TODO(@ansley): Follow-up project needed for full type
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2022-01-05 23:55:49,test/jit/test_upgraders.py,# TODO (tugsuu) We should ideally be generating this test cases.
Jacob Szwejbka,jakeszwe@fb.com,2021-05-24 11:58:33,test/mobile/test_bytecode.py,# TODO update this to be more in the style of the above tests after a backport from 6 -> 5 exists
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/debug_embed_params.py,# TODO: Even better: keyword arguments!
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/pytorch_helper.py,# TODO: handle the case where model cannot be exported
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_operators.py,# TODO: Do an nn style test for these
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: remove this from the final release version
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: figure out the numerical instabilities
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: Why index? This returns a tuple and test runner doesn't
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: Why index? This returns a tuple and test runner doesn't
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: Why index? This returns a tuple and test runner doesn't
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: test with state_dict
bddppq,bai@in.tum.de,2018-05-20 23:37:42,test/onnx/test_caffe2.py,# TODO: Add test cases for prod once Caffe2 has support for ReduceProd
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/test_caffe2.py,# TODO: We should have another pass to eliminate the unused initializers in ONNX models.
Lara,lahaidar@microsoft.com,2019-12-11 20:05:21,test/onnx/test_pytorch_onnx_onnxruntime.py,# TODO: enable bicubic downsample when ORT precision loss fixed
Lara,lahaidar@microsoft.com,2019-10-24 14:19:36,test/onnx/test_pytorch_onnx_onnxruntime.py,# TODO : enable when linear mode is implemented for 1d inputs in ORT
Lara,lahaidar@microsoft.com,2019-10-24 14:19:36,test/onnx/test_pytorch_onnx_onnxruntime.py,# TODO : enable when linear mode is implemented for 3d inputs in ORT
BowenBao,bowbao@microsoft.com,2021-04-22 22:21:06,test/onnx/test_pytorch_onnx_onnxruntime.py,# TODO: value for a_ref is incorrect.
BowenBao,bowbao@microsoft.com,2021-02-04 12:35:27,test/onnx/test_pytorch_onnx_onnxruntime.py,@disableScriptTest()  # TODO: RuntimeError: Exporting the operator __is_ to ONNX is not supported
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/onnx/test_utility_funs.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/onnx/test_utility_funs.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/verify.py,# TODO: Better algorithm for lists
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/verify.py,"# TODO: instead of immediately concatenating the context in the msg,"
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/verify.py,# TODO: onnx should accept iterables
bddppq,bai@in.tum.de,2018-05-11 15:05:18,test/onnx/verify.py,# TODO: test that the traced model also returns the same thing...
Presley Graham,jpgraham@fb.com,2020-05-27 15:29:24,test/quantization/test_backward_compatibility.py,# TODO: graph mode quantized conv2d module
Presley Graham,jpgraham@fb.com,2020-05-27 15:29:24,test/quantization/test_backward_compatibility.py,# TODO: graph mode quantized conv3d module
Presley Graham,jpgraham@fb.com,2020-05-27 15:29:24,test/quantization/test_backward_compatibility.py,# TODO: graph mode quantized conv3d module
Jerry Zhang,jerryzh@fb.com,2020-10-06 23:28:20,test/quantization/test_quantized_op.py,# TODO: enable after observed output is supported in qnnpack
Marjan Fariborz,marjanf@fb.com,2021-08-02 08:55:45,test/quantization/core/test_quantized_op.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Marjan Fariborz,marjanf@fb.com,2021-08-02 08:55:45,test/quantization/core/test_quantized_op.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Zafar,cc.rafaz@zafar.cc,2020-06-23 18:10:31,test/quantization/test_quantized_op.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/quantization/test_quantized_op.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/quantization/test_quantized_op.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Zafar Takhirov,zaf@fb.com,2021-09-08 13:32:29,test/quantization/core/test_quantized_op.py,# TODO: Fix the scripting in the torch/nn/quantizable/modules/rnn.py
Charles David Hernandez,cdhernandez@fb.com,2021-11-15 20:45:24,test/quantization/core/test_quantized_op.py,return  # TODO: fix MakeDeConvOutputShape overflowing for convT3d with qnnpack
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/quantization/test_quantized_tensor.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Supriya Rao,supriyar@fb.com,2020-08-13 11:19:03,test/quantization/test_quantized_tensor.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Charles David Hernandez,cdhernandez@fb.com,2021-07-07 17:15:02,test/quantization/core/test_quantized_tensor.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vasiliy Kuznetsov,vasiliy@fb.com,2020-09-11 14:44:04,test/quantization/test_workflow_module.py,# TODO: enable this (separate PR)
Jerry Zhang,jerryzh@fb.com,2020-04-28 21:29:59,test/quantization/test_workflow_module.py,# TODO: move this to quantize.py
Supriya Rao,supriyar@fb.com,2021-05-26 22:59:21,test/quantization/test_workflow_ops.py,# TODO(future PR): fix the wrong dtype in obs.calculate_qparams and remove the cast
Supriya Rao,supriyar@fb.com,2021-05-26 22:59:21,test/quantization/test_workflow_ops.py,# TODO(future PR): fix the wrong dtype in obs.calculate_qparams and remove the cast
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): move these utils out of the FX folder
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): implement observer sharing to match FX
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,# TODO: make all the math functions work correctly for integer types
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,"# TODO: make the same improvement in FX graph mode quant, if possible"
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): fix this and update this code.
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,"@unittest.skip('FX graph mode is using fake_quantize with PTQ, TODO verify')"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,test/quantization/dbr/test_quantize_dbr.py,# TODO enable scripting support for this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): add FX rewrite support
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-06 13:21:54,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): add FX rewrite support
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-06 13:21:54,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): ensure modules in leaves do not get quantized
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-06 13:21:54,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): we should see if there is a better
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-06 13:21:54,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): enable scripting for ModuleList + DBR
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,test/quantization/dbr/test_quantize_dbr.py,@unittest.skip('TODO build this')
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,test/quantization/dbr/test_quantize_dbr.py,@unittest.skip('TODO fix this')
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): move into a separate test file
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,test/quantization/dbr/test_quantize_dbr.py,"# TODO(future PR): enforce validity of the result above, using"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): consider adding a util for below
Andrew Or,andrewor@fb.com,2022-01-10 17:48:45,test/quantization/dbr/test_quantize_dbr.py,# TODO: Investigate why serialization does not work with functional linear
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,test/quantization/dbr/test_quantize_dbr.py,# TODO(future PR): unbreak this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,test/quantization/dbr/test_quantize_dbr.py,# TODO fix this (reason TBD)
Raghuraman Krishnamoorthi,raghuraman@fb.com,2021-02-04 11:36:46,test/quantization/test_numeric_suite.py,# TODO: Rebase on top of PR to remove compare and validate results here
Jerry Zhang,jerryzh@fb.com,2021-12-16 17:43:38,test/quantization/eager/test_quantize_eager_qat.py,# TODO: if statement only here to tell the jit to skip emitting this when it is None
Jerry Zhang,jerryzh@fb.com,2021-12-16 17:43:38,test/quantization/eager/test_quantize_eager_qat.py,# TODO(jerryzh): extend
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): enable correct weight extraction for these
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): add support for all classes in
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-14 08:59:38,test/quantization/test_numeric_suite_fx.py,"# TODO(future PR): add Linear-ReLU, after #55393 is fixed."
Jerry Zhang,jerryzh@fb.com,2021-07-23 21:28:14,test/quantization/fx/test_numeric_suite_fx.py,"@unittest.skip(""TODO: broken by https://github.com/pytorch/pytorch/pull/61687, will enable later"")"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): clean this up
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-16 10:28:31,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): look into whether shadowing embeddings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-16 10:28:31,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): verify correct I/O for these and remove from
Supriya Rao,supriyar@fb.com,2021-10-06 23:16:42,test/quantization/fx/test_numeric_suite_fx.py,# TODO(future PR): look into whether shadowing embeddings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-16 10:28:31,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): implement shadowing for binary ops
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-16 10:28:31,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): implement shadowing for RNN ops
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-25 22:27:30,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): enable scripting (quant prepared LSTM not scriptable)
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-25 22:27:30,test/quantization/test_numeric_suite_fx.py,# TODO(future PR): enable scripting (quant prepared LSTM not scriptable)
Jerry Zhang,jerryzh@fb.com,2021-07-23 21:28:14,test/quantization/fx/test_numeric_suite_fx.py,"@unittest.skip(""TODO: broken by https://github.com/pytorch/pytorch/pull/61687, will enable later"")"
Jerry Zhang,jerryzh@fb.com,2021-07-23 21:28:14,test/quantization/fx/test_numeric_suite_fx.py,"@unittest.skip(""TODO: broken by https://github.com/pytorch/pytorch/pull/61687, will enable later"")"
Jerry Zhang,jerryzh@fb.com,2020-10-30 12:23:10,test/quantization/test_quantize_fx.py,"# TODO: if we decide to do that in the future, this test needs to"
Jerry Zhang,jerryzh@fb.com,2021-07-28 09:11:53,test/quantization/fx/test_quantize_fx.py,# TODO: add 1d support
Jerry Zhang,jerryzh@fb.com,2021-03-01 14:38:08,test/quantization/test_quantize_fx.py,"# TODO: support call_method(""bmm"")"
Vasiliy Kuznetsov,vasiliy@fb.com,2020-12-16 18:48:01,test/quantization/test_quantize_fx.py,# TODO(future PR): make more generic
Jerry Zhang,jerryzh@fb.com,2021-07-27 02:44:14,test/quantization/fx/test_quantize_fx.py,# TODO: add support for add + torch.relu?
Jerry Zhang,jerryzh@fb.com,2020-08-21 14:28:37,test/quantization/test_quantize_fx.py,# TODO: quantized batchnorm 1d module is missing
Howard Huang,howardhuang@fb.com,2021-04-01 17:59:31,test/quantization/test_quantize_fx.py,"@unittest.skip(""TODO: Test is always failing - https://github.com/pytorch/pytorch/issues/54979"")"
Jerry Zhang,jerryzh@fb.com,2020-04-09 19:16:15,test/quantization/test_quantize_script.py,"# TODO: this is too long, split this to test_insert_observers.py and remove"
Supriya Rao,supriyar@fb.com,2020-06-17 13:38:51,test/quantization/test_quantize_script.py,# TODO: remove after refactor of checkGraphModeOp
Supriya Rao,supriyar@fb.com,2020-06-17 13:38:51,test/quantization/test_quantize_script.py,# TODO: remove after refactor of checkGraphModeOp
Supriya Rao,supriyar@fb.com,2020-06-17 13:38:51,test/quantization/test_quantize_script.py,# TODO: split this after refactor of checkGraphModeOp
Supriya Rao,supriyar@fb.com,2020-06-17 13:38:51,test/quantization/test_quantize_script.py,# TODO: remove after refactor of checkGraphModeOp
Supriya Rao,supriyar@fb.com,2020-06-17 13:38:51,test/quantization/test_quantize_script.py,# TODO: remove after refactor of checkGraphModeOp
Rong Rong,rongr@apache.org,2021-06-11 13:56:06,test/run_test.py,"# TODO: move this logic into common_utils.py instead of passing in ""-k"" individually"
Rong Rong (AI Infra),rongr@fb.com,2021-07-06 09:04:49,test/run_test.py,"# TODO: fix this to use test_times_filename, but currently this is not working"
Rong Rong (AI Infra),rongr@fb.com,2021-07-06 09:04:49,test/run_test.py,# TODO: move this export & download function in tools/ folder
Xiang Gao,qasdfgtyuiop@gmail.com,2019-10-29 11:52:31,test/scripts/run_cuda_memcheck.py,# TODO (@zasdfgbnm): When can we remove this? Will cublas/cudnn run error-free under cuda-memcheck?
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: opinfo this or move to the sparse test suite
gchanan,gregchanan@gmail.com,2018-02-28 10:05:38,test/test_autograd.py,# TODO: t.dtype should work
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: review if this can be ported to OpInfos or moved to test_linalg.py
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: review porting these to OpInfo tests
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: see if this test can be OpInfo'd or moved to diagonal's test suite
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: update these tests to use the linalg module and move to test_linalg.py
Alban Desmaison,albandes@fb.com,2020-01-08 07:13:11,test/test_autograd.py,# and not silent. The TODOs below mark the places with unexpected behavior.
Alban Desmaison,albandes@fb.com,2020-01-08 07:13:11,test/test_autograd.py,# and not silent. The TODOs below mark the places with unexpected behavior.
Jeffrey Wan,jw3468@fb.com,2021-06-22 12:26:42,test/test_autograd.py,# TODO This is not the correct behavior -
Jeffrey Wan,jw3468@fb.com,2021-06-22 12:26:42,test/test_autograd.py,# and not silent. The TODOs below mark the places with unexpected behavior.
Jeffrey Wan,jw3468@fb.com,2021-06-22 12:26:42,test/test_autograd.py,# TODO: this is a bug!
Alban Desmaison,albandes@fb.com,2020-01-08 07:13:11,test/test_autograd.py,# and not silent. The TODOs below mark the places with unexpected behavior.
Alban Desmaison,albandes@fb.com,2020-01-08 07:13:11,test/test_autograd.py,# and not silent. The TODOs below mark the places with unexpected behavior.
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_autograd.py,# TODO: see if these tests can be ported to OpInfos or moved to where's test suite
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_autograd.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
anjali411,chourdiaanjali123@gmail.com,2021-02-03 21:16:58,test/test_autograd.py,# TODO(@anjali411): add an OpInfo based test for torch.cat
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: remove this
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: refactor this out
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: revise the tests to use make_tensor in common_utils.py instead
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: update to use opinfos consistently
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_binary_ufuncs.py,# TODO: below contiguous tensor results are compared with a variety of noncontiguous results.
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_binary_ufuncs.py,# TODO: should this or assertEqual also validate that strides are equal?
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_binary_ufuncs.py,# TODO: review if this skip is necessary
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_binary_ufuncs.py,# TODO: review if this skip is necessary
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_binary_ufuncs.py,# TODO: move to error input test
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,"# TODO: update to work on CUDA, too"
Yukio Siraichi,yukio.siraichi@gmail.com,2021-10-22 18:41:48,test/test_binary_ufuncs.py,# TODO: test all comparison ops after porting them to structured kernel
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,"# TODO: refactor this test into a more generic one, it's parked here currently"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: refactor all these tests using opinfos properly
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: tests like this should be generic
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: what is this test testing?
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: reconcile with minimum/maximum tests
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: refactor to inline these
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_binary_ufuncs.py,# TODO: refactor to use make_tensor
Edward Yang,ezyang@fb.com,2021-03-10 08:50:17,test/test_cpp_extensions_aot.py,# TODO: Rewrite these tests so that they can be collected via pytest without
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_cuda.py,# TODO: reenable multinomial tests if/when the implementation is capturable.
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_cuda.py,"# TODO: reenable normal test, where std is a device"
Tongzhou Wang,tongzhou.wang.1994@gmail.com,2018-10-09 09:51:42,test/test_dataloader.py,# TODO: test the case where the pin_memory_thread triggers an
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_dataloader.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,test/test_dataloader.py,# TODO(VitalyFedyunin): This test will start breaking if we remove guaranteed order
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-09-13 18:48:48,test/test_datapipe.py,@skipIfNoDill  # TODO(VitalyFedyunin): Decouple tests from dill by avoiding lambdas in map
Edward Yang,ezyang@fb.com,2020-03-29 19:46:19,test/test_dispatch.py,# TODO: Expand the dispatcher API to be a generic API for interfacing with
Iurii Zdebskyi,iuriiz@devfair004.maas,2020-08-28 14:32:51,test/test_foreach.py,# TODO: enable empty list case
Nikita Shulga,nshulga@fb.com,2020-07-23 12:53:55,test/test_futures.py,"@unittest.skipIf(IS_WINDOWS, ""TODO: need to fix this testcase for Windows"")"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_indexing.py,# TODO: enable one indexing is implemented like in numpy
vfdev-5,vfdev.5@gmail.com,2021-11-08 17:55:03,test/test_indexing.py,# TODO: replace with a better solution.
Elias Ellison,eellison@fb.com,2020-07-29 10:14:41,test/test_jit.py,# TODO: setting false on test itself is not working
Nikolay Korovaiko,korovaikon@gmail.com,2020-09-13 15:56:30,test/test_jit.py,# TODO: enable TE in PE when all tests are fixed
James Reed,jamesreed@fb.com,2019-08-09 17:22:46,test/test_jit.py,"# x.dtype, TODO: dtype long -> instance conversion"
James Reed,jamesreed@fb.com,2019-09-30 19:28:58,test/test_jit.py,# x.layout TODO: layout long -> instance conversion
Richard Zou,zou3519@gmail.com,2018-12-11 14:50:33,test/test_jit.py,# TODO: adapt this test to check that GraphExecutor treats them differently
Richard Zou,zou3519@gmail.com,2018-12-11 14:50:33,test/test_jit.py,# TODO: update verify to work with GraphExecutors
Richard Zou,zou3519@gmail.com,2018-12-11 14:50:33,test/test_jit.py,# TODO: adapt to a GraphExecutor test
Ailing Zhang,ailzhang@fb.com,2020-07-06 13:07:51,test/test_jit.py,# TODO(#40882): previously we assert exact matches between eager and JIT result:
Yanan Cao,gmagogsfm@gmail.com,2020-07-24 11:37:11,test/test_jit.py,# TODO(gmagogsfm): Refactor this test to reduce complexity.
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_jit.py,"@unittest.skipIf(True, ""TODO: re-enable with https://github.com/pytorch/pytorch/pull/29339"")"
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_jit.py,"@unittest.skipIf(IS_WINDOWS, 'TODO: fix occasional windows failure')"
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_jit.py,"@unittest.skipIf(IS_WINDOWS and sys.version_info >= (3, 8), 'TODO: need to fix the test case')"
Nikolay Korovaiko,korovaikon@gmail.com,2020-06-10 13:46:11,test/test_jit.py,# TODO: simplify this test as it's very sensitive
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_jit.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Tugrul Ince,ince@fb.com,2020-03-13 12:49:41,test/test_jit.py,# TODO we need to test exponent operator '**' and bitwise not
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_jit.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
davidriazati,davidriazati@fb.com,2019-06-20 11:11:07,test/test_jit.py,# TODO: add more tests when bool conversions ready
davidriazati,davidriazati@fb.com,2019-06-20 11:11:07,test/test_jit.py,# TODO: add param mutation test case after JIT support it
Shen Li,shenli@fb.com,2021-08-12 11:39:31,test/test_jit.py,TODO: we should actually check these conditions once we have a way
davidriazati,davidriazati@fb.com,2019-06-20 11:11:07,test/test_jit.py,# TODO: this should be supported but is difficult to parse
Michael Suo,suo@fb.com,2020-07-13 16:57:41,test/test_jit.py,with torch._jit_internal._disable_emit_hooks():  # TODO: Python print broadcasting list
Ansley Ussery,ansley@fb.com,2021-06-26 15:17:10,test/test_jit.py,# TODO: We can't use `checkScript` with the NamedTuple factory
Elias Ellison,eellison@fb.com,2019-08-07 19:11:55,test/test_jit.py,# TODO: pyflakes currently does not compose @overload annotation with other
Elias Ellison,eellison@fb.com,2019-08-07 19:11:55,test/test_jit.py,# overload as well - TODO take them from implementation and apply
davidriazati,davidriazati@fb.com,2019-06-20 11:11:07,test/test_jit.py,# TODO: re-enable module hook when Python printing of attributes is
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_jit.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Nikita Vedeneev,nik@quansight.com,2020-10-23 10:11:05,test/test_jit.py,# TODO(@nikitaved) Enable jit tests once autograd.Function does support scripting
Michael Dagitses,mikeyd@fb.com,2021-06-22 10:09:25,test/test_jit.py,# TODO(issue#52052) Neither this nor no_grad should be required
jjsjann123,alex.jann2012@gmail.com,2021-10-27 12:09:53,test/test_jit_autocast.py,# TODO: fix and enable this test?
jjsjann123,alex.jann2012@gmail.com,2021-11-17 01:20:26,test/test_jit_cuda_fuser.py,# TODO: update accuracy tolerance for bf16 / fp16 data types
jjsjann123,alex.jann2012@gmail.com,2021-11-17 01:20:26,test/test_jit_cuda_fuser.py,# TODO: Add Tensor support for clamp
jjsjann123,alex.jann2012@gmail.com,2021-11-17 01:20:26,test/test_jit_cuda_fuser.py,# TODO: we could preserve permutation to inputs
jiej,jiej@nvidia.com,2021-09-22 04:53:03,test/test_jit_cuda_fuser.py,"# (TODO) check executed kernel, should extend autograd.profiler to fused"
jiej,jiej@nvidia.com,2021-09-22 04:53:03,test/test_jit_cuda_fuser.py,"# (TODO) check executed kernel, should extend autograd.profiler to fused"
jiej,jiej@nvidia.com,2021-09-22 04:53:03,test/test_jit_cuda_fuser.py,# TODO: remove this run?
jiej,jiej@nvidia.com,2021-09-22 04:53:03,test/test_jit_cuda_fuser.py,# TODO: switch to welford and reduce this to 1e-5
Elias Ellison,eellison@fb.com,2019-03-29 18:10:36,test/test_jit_fuser.py,# TODO: add optionally enabled debug counters to the fuser to verify
Michael Suo,suo@fb.com,2019-07-16 11:59:53,test/test_jit_fuser.py,# TODO: We leak CUDA memory here because the traced graph holds onto a
Elias Ellison,eellison@fb.com,2019-03-29 18:10:36,test/test_jit_fuser.py,# TODO: Fuser doesn't work at all when inputs require grad. Fix that
Elias Ellison,eellison@fb.com,2020-11-12 11:06:50,test/test_jit_fuser_te.py,"# TODO: force LLVM. need to add it to asan, mac, windows builds + sandcastle"
Mikhail Zolotukhin,mvz@fb.com,2020-03-20 13:04:21,test/test_jit_fuser_te.py,# TODO: add optionally enabled debug counters to the fuser to verify
Mikhail Zolotukhin,mvz@fb.com,2020-03-20 13:04:21,test/test_jit_fuser_te.py,# TODO: We leak CUDA memory here because the traced graph holds onto a
Elias Ellison,eellison@fb.com,2020-11-12 11:06:50,test/test_jit_fuser_te.py,# TODO: uncomment when TE enables support for scalar tensors
Mikhail Zolotukhin,mvz@fb.com,2020-09-15 21:28:37,test/test_jit_fuser_te.py,# TODO: we're currently not checking 'device' in the type info when pulling
Mikhail Zolotukhin,mvz@fb.com,2020-03-20 13:04:21,test/test_jit_fuser_te.py,# TODO: Fuser doesn't work at all when inputs require grad. Fix that
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_jit_fuser_te.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mikhail Zolotukhin,mvz@fb.com,2020-08-25 18:09:55,test/test_jit_fuser_te.py,# TODO: fix that and reenable the test.
Bert Maher,bertrand@fb.com,2021-08-30 18:36:33,test/test_jit_fuser_te.py,# TODO: Add back when https://github.com/pytorch/pytorch/issues/55905 is closed
Bert Maher,bertrand@fb.com,2021-04-15 13:57:19,test/test_jit_fuser_te.py,# TODO: Add back when https://github.com/pytorch/pytorch/issues/55905 is closed
Bert Maher,bertrand@fb.com,2021-08-30 18:36:33,test/test_jit_fuser_te.py,# TODO: Add back when https://github.com/pytorch/pytorch/issues/55905 is closed
Bert Maher,bertrand@fb.com,2021-08-30 20:08:15,test/test_jit_fuser_te.py,# TODO: broken on ROCm?
Bert Maher,bertrand@fb.com,2021-08-30 18:36:33,test/test_jit_fuser_te.py,# TODO: Add back when https://github.com/pytorch/pytorch/issues/55905 is closed
Mikhail Zolotukhin,mvz@fb.com,2021-04-16 12:52:51,test/test_jit_fuser_te.py,# TODO: add support for other shape combinations and make this set empty:
Mikhail Zolotukhin,mvz@fb.com,2021-06-18 11:53:39,test/test_jit_fuser_te.py,"# TODO: once the adaptive_avg_pool2d is available in OpInfo DB, this"
Animesh Jain,anijain@fb.com,2022-01-06 16:20:13,test/test_jit_fuser_te.py,"# TODO: force LLVM. need to add it to asan, mac, windows builds + sandcastle"
Kurt Mohler,kmohler@quansight.com,2020-08-28 18:26:41,test/test_linalg.py,# TODO: Remove this function once the broken cases are fixed
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_linalg.py,@onlyNativeDeviceTypes   # TODO: XLA doesn't raise exception
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_linalg.py,@onlyNativeDeviceTypes   # TODO: XLA doesn't raise exception
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_linalg.py,"# TODO: update to run on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_linalg.py,"# TODO: update to run on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_linalg.py,# TODO (@zasdfgbnm): this causes the following error on test
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_linalg.py,# TODO: update to compare against NumPy
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_linalg.py,"# TODO: technically we need subexponential distn for this to hold,"
XiaobingSuper,xiaobing.zhang@intel.com,2021-02-18 10:16:16,test/test_mkldnn.py,# TODO: enable conv1d training.
XiaobingSuper,xiaobing.zhang@intel.com,2021-03-15 13:25:01,test/test_mkldnn.py,# TODO: support 3d batchnorm training.
XiaobingSuper,xiaobing.zhang@intel.com,2021-03-15 13:25:01,test/test_mkldnn.py,# TODO: support none affine.
"Zhang, Xiaobing",xiaobing.zhang@intel.com,2020-07-15 13:51:59,test/test_mkldnn.py,# TODO: support training
Vasiliy Kuznetsov,vasiliy@fb.com,2020-08-08 15:49:38,test/test_mobile_optimizer.py,# TODO: test nn.Sequential after #42039 is fixed
Joel Schlosser,jbschlosser@fb.com,2021-04-22 16:15:32,test/test_module_init.py,# TODO: Merge this in with the initial ModuleInfo implementation.
Joel Schlosser,jbschlosser@fb.com,2021-04-22 16:15:32,test/test_module_init.py,# TODO: Remove these 2 from this list once the ASan issue is fixed.
Joel Schlosser,jbschlosser@fb.com,2021-07-27 07:34:51,test/test_modules.py,# TODO: Handle precision
Soumith Chintala,soumith@gmail.com,2017-05-18 22:20:50,test/test_multiprocessing.py,# TODO: Disabled because this check is too flaky
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_multiprocessing.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Richard Zou,zou3519@gmail.com,2019-09-12 06:29:19,test/test_namedtensor.py,"# TODO(rzou): It would be nice for this to be a ""real"" python warning."
Richard Zou,zou3519@gmail.com,2019-08-14 06:16:00,test/test_namedtensor.py,# TODO(rzou): Some form of this check should be added to self.assertEqual.
Mike Ruberry,mruberry@devfair044.maas,2019-10-08 09:50:28,test/test_nn.py,# TODO: remove this global setting
Michela Paganini,micky.91@hotmail.com,2019-11-08 19:35:46,test/test_nn.py,# TODO: add other modules
Michela Paganini,micky.91@hotmail.com,2019-11-08 19:35:46,test/test_nn.py,# TODO: add other modules
Michela Paganini,micky.91@hotmail.com,2019-11-08 19:35:46,test/test_nn.py,# TODO: add other modules
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Richard Zou,zou3519@gmail.com,2021-01-22 07:38:07,test/test_nn.py,# TODO(#50743): the following segfaults with check_batched_grad=True
soulitzer,soulitzer@gmail.com,2021-11-03 15:24:10,test/test_nn.py,# TODO: Create an OpInfo for pdist
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Adam Paszke,adam.paszke@gmail.com,2016-08-19 14:23:07,test/test_nn.py,# TODO: CUDA is not implemented yet
Xiao Wang,24860335+xwang233@users.noreply.github.com,2020-09-17 18:58:02,test/test_nn.py,# TODO: fix numerical issue. See #44863
Xiao Wang,24860335+xwang233@users.noreply.github.com,2020-09-17 18:58:02,test/test_nn.py,# TODO: fix numerical issue. See #44863
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_nn.py,@onlyNativeDeviceTypes   # TODO: fix on XLA
Mike Ruberry,mruberry@devfair044.maas,2019-10-02 11:30:01,test/test_nn.py,# TODO: figure out why precision on sparse embeddings isn't the
Peter Bell,peterbell10@live.co.uk,2021-07-23 09:53:30,test/test_nn.py,"# TODO: Test fails with cudnn, see gh-62034"
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_nn.py,@onlyNativeDeviceTypes  # TODO: Fails on XLA
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_nn.py,@onlyNativeDeviceTypes  # TODO: Fails on XLA
kshitij12345,kshitijkalambarkar@gmail.com,2021-11-01 09:21:20,test/test_nn.py,@onlyNativeDeviceTypes  # TODO: RuntimeError message different on XLA
Heitor Schueroff de Souza,heitorschueroff@fb.com,2020-09-01 08:38:41,test/test_nn.py,# TODO(Heitor) change once with_indices code is updated
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_numpy_interop.py,# TODO: change to tensor equality check once HalfTensor
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_numpy_interop.py,# TODO: Imaginary part is dropped in this case. Need fix.
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_ops.py,# TODO: fixme https://github.com/pytorch/pytorch/issues/68972
Mike Ruberry,mruberry@fb.com,2021-10-29 09:52:24,test/test_ops.py,# TODO: get working with Windows by addressing failing operators
Mike Ruberry,mruberry@fb.com,2021-10-29 09:52:24,test/test_ops.py,# TODO: get working with ASAN by addressing failing operators
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,test/test_ops.py,# TODO: verify the op doesn't support the out= kwarg
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,test/test_ops.py,# TODO: verify the op doesn't support the out= kwarg
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-07 08:18:56,test/test_ops.py,# TODO: Check grad for all Tensors requiring grad if sample.input is TensorList
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-07 08:18:56,test/test_ops.py,# TODO: backward consistency only supported for single tensor outputs
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-07 08:18:56,test/test_ops.py,"# TODO: backward consistency only checked on sample.input, not all"
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-07 08:18:56,test/test_ops.py,# TODO: update to handle checking grads of all tensor inputs as
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-15 07:38:13,test/test_ops.py,# TODO Support non-tensor outputs if they exist for inplace ops
soulitzer,soulitzer@gmail.com,2021-11-19 14:24:01,test/test_ops.py,# TODO: clean up how attributes are passed to gradcheck from OpInfos
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,test/test_ops.py,"# TODO WARNING: inplace x {traced, scripted} not currently tested"
Elias Ellison,eellison@devfair044.h1.fair,2021-08-10 09:40:41,test/test_ops.py,"# TODO: inplace tests currently fail, fix and add inplace variant"
Elias Ellison,eellison@devfair044.h1.fair,2021-08-10 09:40:41,test/test_ops.py,# TODO: find better way to standardize on op registration itself..
Elias Ellison,eellison@devfair044.h1.fair,2021-08-10 09:40:41,test/test_ops.py,# TODO: fix tracing here
Elias Ellison,eellison@devfair044.h1.fair,2021-09-07 18:19:14,test/test_ops.py,# TODO: no reason why we cant run this with tracing graph
Elias Ellison,eellison@devfair044.h1.fair,2021-08-10 09:40:41,test/test_ops.py,# TODO: use script graph as well
Elias Ellison,eellison@devfair044.h1.fair,2021-09-15 13:43:12,test/test_ops.py,# TODO: list of tensor outputs
Anjali Chourdia,chourdiaanjali@fb.com,2021-07-13 13:49:22,test/test_ops.py,# TODO: add tests for `R->C` functions
Anjali Chourdia,chourdiaanjali@fb.com,2021-07-13 13:49:22,test/test_ops.py,# TODO: backward consistency only supported for single tensor outputs
Anjali Chourdia,chourdiaanjali@fb.com,2021-07-13 13:49:22,test/test_ops.py,"# TODO: backward consistency only checked on sample.input, not all"
Anjali Chourdia,chourdiaanjali@fb.com,2021-07-13 13:49:22,test/test_ops.py,# TODO: update to handle checking grads of all tensor inputs as
Edward Yang,ezyang@fb.com,2021-06-25 11:49:20,test/test_python_dispatch.py,# TODO: figure out why broken
Edward Yang,ezyang@fb.com,2021-06-25 11:49:20,test/test_python_dispatch.py,# TODO: arguably this shouldn't pass and we should complain
Edward Yang,ezyang@fb.com,2021-06-25 11:49:20,test/test_python_dispatch.py,# TODO: figure out why x.requires_grad = False doesn't
Edward Yang,ezyang@fb.com,2021-06-25 11:49:20,test/test_python_dispatch.py,# TODO: figure out why this is broken
Supriya Rao,supriyar@fb.com,2021-05-27 17:01:13,test/test_quantization.py,# TODO: merge the different quantized op tests into one test class
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: replace with make_tensor
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: replace with make_tensor
Heitor Schueroff,heitorschueroff@fb.com,2021-08-26 07:17:24,test/test_reductions.py,# TODO(@heitorschueroff) combine cases with and without keepdim once
Heitor Schueroff,heitorschueroff@fb.com,2021-08-26 07:17:24,test/test_reductions.py,# TODO(@heitorschueroff) Update these to use the nan_policy kwarg once
Heitor Schueroff,heitorschueroff@fb.com,2021-08-26 06:05:28,test/test_reductions.py,# TODO: Legacy tests - port to ReductionOpInfo
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: kill map2_ (and similar) uses and update to compare with NumPy
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: kill this ane replace with common creation ops
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: refactor this to use comparators from common_utils
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: update this and tests that use it to use the device argument properly
Peter Bell,peterbell10@live.co.uk,2021-04-09 10:01:48,test/test_reductions.py,# TODO: update this and tests that use it to handle device properly
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,"# TODO: make work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: this should be a generic opinfo test
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: bincount isn't a classic reduction -- maybe this test suite is
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: how many var stability tests are there?
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: consider refactoring with bincount test
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: Investigate why the output is not close to numpy.
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,"# TODO: part of this test covers torch.norm, with should be covered by test_linalg"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: update this test to comapre against NumPy
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: update this test to compare against NumPy
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: update this to compare against NumPy instead of CPU
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: update this to compare against NumPy instead of CPU
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_reductions.py,# TODO: make this test generic using OpInfos
sanchit,sanchit@node-0.amd.uwmadison744-f18-pg0.clemson.cloudlab.us,2021-03-23 03:36:21,test/test_reductions.py,# TODO: torch.min does not support the same operation as argmin
soulitzer,soulitzer@gmail.com,2021-11-03 15:24:10,test/test_reductions.py,# TODO: can these be merged with their respective OpInfos?
Serhat Yilmaz,serhaty@fb.com,2021-06-17 16:23:15,test/test_segment_reductions.py,# TODO: calculate grad and check correctness
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_shape_ops.py,# TODO: replace with make_tensor
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_shape_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_shape_ops.py,"# TODO: update to work on CUDA, too?"
Mike Ruberry,mruberry@devfair044.maas,2021-02-04 17:40:31,test/test_shape_ops.py,# TODO: update once warning flag is available to always trigger ONCE warnings
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_sort_and_select.py,# TODO: remove this
Edward Z. Yang,ezyang@mit.edu,2017-05-03 05:43:03,test/test_sparse.py,# TODO: Put this in torch.cuda.randn
Soumith Chintala,soumith@gmail.com,2017-04-28 15:26:29,test/test_sparse.py,# TODO: add back inplace support
Alexander,aocsa.cs@gmail.com,2021-04-09 12:16:06,test/test_sparse.py,"# TODO: This is also testing that, if coalesce is a no-op,"
Alexander,aocsa.cs@gmail.com,2021-04-09 12:16:06,test/test_sparse.py,# TODO: Check after why ROCm's cusparseXcsrgemm2Nnz function doesn't return the same nnz value as CUDA
Ivan Yashchuk,ivan.yashchuk@aalto.fi,2021-09-21 13:02:14,test/test_sparse.py,# TODO: Check this cuSparse issue.
Alexander,aocsa.cs@gmail.com,2021-06-01 21:15:20,test/test_sparse_csr.py,# TODO: Support auto generation of device check for sparse tensors
Ivan Yashchuk,ivan.yashchuk@aalto.fi,2021-12-16 12:57:54,test/test_sparse_csr.py,# TODO: replace with torch method when implemented to_dense() on block sparse tensor
Peter Bell,peterbell10@live.co.uk,2020-09-19 23:30:38,test/test_spectral_ops.py,# TODO: Remove torch.half error when complex32 is fully implemented
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: refactor tri_tests_args, _compare_trilu_indices, run_additional_tri_tests"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: replace with make_tensor
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: replace with make_tensor
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: remove this when bool and half are supported for torch.where
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: reconcile with other cat tests
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: Compare with a NumPy reference instead of CPU
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: update this test to compare against NumPy instead of CPU
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO: re-enable this test
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: udpate to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too?"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too?"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: update to work on CUDA, too?"
Michael Dagitses,mikeyd@fb.com,2021-09-16 09:58:09,test/test_tensor_creation_ops.py,# TODO Eliminate this and replace it with a list of all
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO investigate rounding errors
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,# TODO investigate rounding errors
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: This test probably doesn't make too much sense now that
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_tensor_creation_ops.py,"# TODO: add torch.complex64, torch.complex128"
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Edward Yang,ezyang@fb.com,2021-04-27 07:25:46,test/test_tensor_creation_ops.py,# TODO: This won't actually work for non-CUDA device
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Mike Ruberry,mruberry@devfair044.maas,2020-08-22 23:16:40,test/test_tensor_creation_ops.py,# TODO: this test should be updated
Elias Ellison,eellison@devfair044.maas,2020-10-08 11:59:57,test/test_tensorexpr.py,# TODO: reenable. Currently all of the tests fail
Mikhail Zolotukhin,mvz@fb.com,2020-10-16 20:22:11,test/test_tensorexpr.py,# TODO: Fix and re-enable the test.
Philip Meier,github.pmeier@posteo.de,2021-08-30 12:28:39,test/test_testing.py,# TODO: the code that this test was designed for was removed in https://github.com/pytorch/pytorch/pull/56058
Philip Meier,github.pmeier@posteo.de,2021-06-23 21:57:51,test/test_testing.py,# TODO: replace this by actual.clone() after https://github.com/pytorch/pytorch/issues/59285 is fixed
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_torch.py,# TODO: move all tensor creation to common ops
Gregory Chanan,gchanan@fb.com,2019-11-27 14:48:05,test/test_torch.py,"# TODO: this behavior differs on CPU and GPU, see https://github.com/pytorch/pytorch/issues/30480."
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_torch.py,# TODO: this test should be in test_nn.py
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_torch.py,# TODO: this test should be in test_nn.py
Sameer Deshmukh,sameer.deshmukh93@gmail.com,2020-06-29 15:50:03,test/test_torch.py,# TODO: remove this after scatter_add_ is deprecated.
Mike Ruberry,mruberry@devfair044.maas,2019-09-19 01:47:32,test/test_torch.py,# TODO: if we had operator introspection we could figure out this set of operators automatically...
Emilio Castillo,ecastill@preferred.jp,2021-09-12 19:45:57,test/test_torch.py,# TODO: increase tests once NumPy supports the `__dlpack__` protocol
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,test/test_torch.py,"# TODO: Pytorch uses fixed precision to print, while Numpy uses dragon4_scientific"
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,test/test_torch.py,# TODO: this test should be triggered by test_nn.py but right
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,test/test_torch.py,# TODO: the out tests cannot be triggered by test_nn.py because
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,test/test_torch.py,# TODO: the out tests cannot be triggered by test_nn.py because
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,test/test_torch.py,# TODO: add torch.* tests when we have proper namespacing on ATen functions
Edward Yang,ezyang@fb.com,2021-06-03 10:47:19,test/test_torch.py,# multithreaded-ly) (TODO: except maybe if you can prove that
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,test/test_torch.py,# TODO: these empy classes are temporarily instantiated for XLA compatibility
Sam Estep,sam@samestep.com,2021-04-19 15:25:48,test/test_type_hints.py,"# TODO: Would be better not to chdir here, this affects the"
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_type_promotion.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_type_promotion.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,test/test_type_promotion.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2020-08-20 21:59:49,test/test_unary_ufuncs.py,# TODO: port test_unary_out_op_mem_overlap
Mike Ruberry,mruberry@devfair044.maas,2020-08-20 21:59:49,test/test_unary_ufuncs.py,# TODO: add test for inplace variants erroring on broadcasted inputs
Mike Ruberry,mruberry@devfair044.maas,2020-09-10 17:29:44,test/test_unary_ufuncs.py,# TODO: should this or assertEqual also validate that strides are equal?
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO resolve with opinfos
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: run on non-native device types
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: opinfo hardshrink
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: allow large opinfo values to be opted-into via metadata
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: add signed zero testing to opinfos
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: update to compare against NumPy by rationalizing with OpInfo
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_unary_ufuncs.py,# TODO: rationalize with exp OpInfo
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: replace this with make_tensor() in common_utils.py
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: replace this with make_tensor() in common_utils.py
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: refactor tests to avoid this function
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: replace this with make_tensor() in common_utils.py
Kurt Mohler,kmohler@quansight.com,2021-11-11 13:53:22,test/test_view_ops.py,# TODO: Remove this when autograd support is added
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: Add torch.ComplexHalfStorage
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: Add torch.ComplexHalfStorage
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: Add torch.ComplexHalfStorage
soulitzer,soulitzer@gmail.com,2021-11-03 15:24:10,test/test_view_ops.py,# TODO: opinfo this or move to unbind's test suite
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: this should be refactored into the view ops test suite
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: this should be refactored into the view ops test suite
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: this should be refactored into the view ops test suite
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: fix these once we have multi-dimensional empty tensors
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,"# TODO: update to work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,"# TODO: make work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,"# TODO: make work on CUDA, too"
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: is resize best put in test_view_ops?
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,test/test_view_ops.py,# TODO: are these view ops?
soulitzer,soulitzer@gmail.com,2021-11-03 15:24:10,test/test_view_ops.py,# TODO: OpInfo this
Richard Zou,zou3519@gmail.com,2020-06-30 08:16:32,test/test_vmap.py,# TODO(rzou): This error message isn't that great. It comes straight
Richard Zou,zou3519@gmail.com,2020-09-15 10:39:44,test/test_vmap.py,# TODO(rzou): fix the following
driazati,driazati@users.noreply.github.com,2021-05-24 13:49:47,tools/actions_local_runner.py,# TODO: Either lint that GHA scripts only use 'set -eux' or make this more
Jeff Daily,jeff.daily@amd.com,2020-07-22 09:39:13,tools/amd_build/build_amd.py,# TODO Remove once gloo submodule is recent enough to contain upstream fix.
Jeff Daily,jeff.daily@amd.com,2021-01-22 07:20:07,tools/amd_build/build_amd.py,# TODO Remove once gloo submodule is recent enough to contain upstream fix.
Sam Gross,colesbury@gmail.com,2017-12-27 15:59:41,tools/autograd/gen_autograd_functions.py,"# TODO: This is probably not exhaustive, but it's a start"
Ailing Zhang,ailzhang@fb.com,2021-03-11 21:18:16,tools/autograd/gen_inplace_or_view_type.py,# TODO: Should handle optional here?
Ailing Zhang,ailzhang@fb.com,2021-03-11 21:18:16,tools/autograd/gen_inplace_or_view_type.py,# TODO: Should handle optional here?
Ailing Zhang,ailzhang@fb.com,2021-03-11 21:18:16,tools/autograd/gen_inplace_or_view_type.py,return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
Jiakai Liu,liujiakai@fb.com,2020-11-08 01:03:59,tools/autograd/gen_python_functions.py,# TODO: should use some canonical form instead of 'str(arg.type)' - see comments
Kurt Mohler,kurtamohler@gmail.com,2020-10-28 09:31:02,tools/autograd/gen_python_functions.py,# TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
Jiakai Liu,liujiakai@fb.com,2020-11-09 11:55:37,tools/autograd/gen_trace_type.py,# TODO: byte-for-byte compatible with old codegen behavior - should clean up
Jiakai Liu,liujiakai@fb.com,2020-11-09 11:55:37,tools/autograd/gen_trace_type.py,# TODO: byte-for-byte compatible with old codegen behavior - it's incorrect to assume
Edward Yang,ezyang@fb.com,2020-12-02 07:47:13,tools/autograd/gen_trace_type.py,name = f.func.arguments.out[0].name  # TODO: old codegen behavior - should fix
Jiakai Liu,liujiakai@fb.com,2020-11-09 11:55:37,tools/autograd/gen_trace_type.py,# TODO: clean up old codegen behavior
Jiakai Liu,liujiakai@fb.com,2020-11-14 13:03:29,tools/autograd/gen_variable_factories.py,# TODO: maybe update the cpp argument API to take optional namespace argument?
soulitzer,soulitzer@gmail.com,2021-08-27 14:59:08,tools/autograd/gen_variable_type.py,# TODO: it would be nice to not have these special cases
Jiakai Liu,liujiakai@fb.com,2021-01-05 14:00:02,tools/autograd/gen_variable_type.py,"# TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove."
Jiakai Liu,liujiakai@fb.com,2021-01-05 14:00:02,tools/autograd/gen_variable_type.py,# TODO: should be `arg.type.is_tensor_like()`?
Jeffrey Wan,jw3468@fb.com,2021-06-30 19:17:40,tools/autograd/gen_variable_type.py,base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
Edward Z. Yang,ezyang@mit.edu,2018-05-10 10:28:33,tools/autograd/gen_variable_type.py,"# TODO: flatten allocates a std::vector, which could be expensive"
albanD,desmaison.alban@gmail.com,2021-07-27 13:03:24,tools/autograd/gen_variable_type.py,# TODO update this when inplace namings are unified
Jiakai Liu,liujiakai@fb.com,2020-11-19 21:44:43,tools/autograd/load_derivatives.py,# TODO: do we need eagerly calculate and save it here? Can it be derived
Jiakai Liu,liujiakai@fb.com,2020-11-19 21:44:43,tools/autograd/load_derivatives.py,# TODO: maybe the logic to handle the legacy schema is no longer necessary?
Martin Yuan,myuan@fb.com,2020-11-08 15:20:23,tools/code_analyzer/gen_op_registration_allowlist.py,"# TODO: when FL is migrated from full-jit to lite trainer, remove '__ROOT__'"
yujunzhao@devvm229.ftw0.facebook.com,yujunzhao@devvm229.ftw0.facebook.com,2020-08-28 13:52:59,tools/code_coverage/package/oss/utils.py,# TODO: change the way we get binary file -- binary may not in build/bin ?
yujunzhao@devvm229.ftw0.facebook.com,yujunzhao@devvm229.ftw0.facebook.com,2020-08-28 13:52:59,tools/code_coverage/package/oss/utils.py,# TODO use glob
Jiakai Liu,liujiakai@fb.com,2020-11-19 21:44:43,tools/codegen/api/autograd.py,# TODO: maybe the logic to search for all variants is no longer necessary?
Jiakai Liu,liujiakai@fb.com,2021-01-05 14:00:02,tools/codegen/api/autograd.py,"# TODO: only to keep it byte-for-byte compatible with the old codegen, should remove."
Jiakai Liu,liujiakai@fb.com,2021-01-05 14:00:02,tools/codegen/api/autograd.py,#   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
Jiakai Liu,liujiakai@fb.com,2021-01-05 14:00:02,tools/codegen/api/autograd.py,"# TODO: only to keep it byte-for-byte compatible with the old codegen, should remove."
Ailing Zhang,ailzhang@fb.com,2021-03-11 19:48:12,tools/codegen/api/autograd.py,# TODO: Update comment below since it is out of date.
Brian Hirsh,hirsheybar@fb.com,2021-04-16 11:40:22,tools/codegen/api/cpp.py,"return NamedCType(binds, MutRefCType(BaseCType(tensorT)))  # TODO: fix this discrepancy"
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/api/cpp.py,"# TODO: remove these special cases, ArrayRef fallthrough works fine"
Jiakai Liu,liujiakai@fb.com,2020-11-09 11:55:37,tools/codegen/api/cpp.py,# TODO: Consider incorporating this into the data model
Edward Yang,ezyang@fb.com,2020-12-16 16:15:52,tools/codegen/api/cpp.py,default = 'at::kLong'  # TODO: this is wrong
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/api/lazy.py,"raise AssertionError(f""TODO add support for type {repr(typ)}"")"
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/api/lazy.py,# TODO(whc) is this actually correct? or should it use a Vector like above
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/api/lazy.py,# TODO: Need to handle collisions with argument names at some point
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/api/legacy_dispatcher.py,# TODO: delete this!
Wenlei Xie,wxie@fb.com,2021-03-31 16:19:52,tools/codegen/api/native.py,# TODO: Not sure why the arguments assigned here are for
Brian Hirsh,hirsheybar@fb.com,2020-12-11 13:24:55,tools/codegen/api/python.py,"# [old codegen] TODO: remove this? doesn't rename in codegen, it's just"
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,"# [old codegen] TODO: remove this? doesn't rename in codegen, it's just"
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: maybe don't need keep scattered out fields for python signature?
Brian Hirsh,hirsheybar@fb.com,2020-12-07 10:37:38,tools/codegen/api/python.py,"# TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?"
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: create a dedicated SelfArgument type for 'self'?
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: maybe create a PythonTensorOptionsArgument?
Jiakai Liu,liujiakai@fb.com,2020-10-28 21:21:12,tools/codegen/api/python.py,# TODO: fix this special case in PythonArgParser?
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: directly translate a.default to python default
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# [old codegen] TODO: because these aren't guaranteed to be 100% faithful
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO blowtorch
Brian Hirsh,hirsheybar@fb.com,2020-12-11 13:24:55,tools/codegen/api/python.py,# TODO: this doesn't seem right...
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: avoid this special handling?
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: why this needs to be special case?
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,"# TODO: make this part of something more general, or get rid of it."
Jiakai Liu,liujiakai@fb.com,2020-10-19 17:34:45,tools/codegen/api/python.py,# TODO: maybe move to the generator side as it's not related to binding.
Edward Yang,ezyang@fb.com,2021-02-03 13:57:56,tools/codegen/api/structured.py,# TODO: delete these special cases; see tools.codegen.api.cpp--these
Edward Yang,ezyang@fb.com,2021-02-04 09:10:34,tools/codegen/api/translate.py,# TODO: My kingdom for a pattern matcher
Edward Yang,ezyang@fb.com,2021-02-04 09:10:34,tools/codegen/api/translate.py,# TODO: This could get us in recomputation trouble if b.expr is nontrivial
Brian Hirsh,hirsheybar@fb.com,2021-04-16 11:40:22,tools/codegen/api/types.py,# TODO: Kill this when we eventually remove it!
Brian Hirsh,hirsheybar@fb.com,2021-04-16 11:40:22,tools/codegen/api/types.py,# TODO: Kill this when we eventually remove it!
Edward Yang,ezyang@fb.com,2020-12-16 16:15:52,tools/codegen/api/types.py,# TODO: maybe don't represent default here
Brian Hirsh,hirsheybar@fb.com,2021-04-16 11:40:22,tools/codegen/api/types.py,# TODO: Kill this when we eventually remove it!
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,"raise AssertionError(""TODO not sure if there are other valid types to handle here"")"
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,"raise AssertionError(""TODO not sure if there are other valid types to handle here"")"
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,// TODO(alanwaketan): Public members don't need to have _ suffix.
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,"# TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it"
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,"raise AssertionError(""TODO not sure if there are other valid types to handle here"")"
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ir.py,// TODO(alanwaketan): Quite a lot inefficient copy-by-value there. Let's optimize it.
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ts_lowering.py,"assert len(schema.keyword_values) == 0, ""TODO the logic for operand(i) is broken if there are kw values"""
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/dest/lazy_ts_lowering.py,// TODO: need to call GenerateClone sometimes? Or else return LowerBuiltIn() directly
Brian Hirsh,hirsheybar@fb.com,2021-05-17 12:21:27,tools/codegen/dest/register_dispatch_key.py,# TODO: handle in place on tensor list
Edward Yang,ezyang@fb.com,2021-02-04 09:10:34,tools/codegen/dest/register_dispatch_key.py,# TODO: Make sure out argument is guaranteed to be self
Edward Yang,ezyang@fb.com,2021-03-02 14:05:21,tools/codegen/dest/register_dispatch_key.py,"# TODO: Now, there is something interesting going on here.  In the code below,"
Edward Yang,ezyang@fb.com,2021-02-04 09:10:34,tools/codegen/dest/register_dispatch_key.py,"# (e.g., at::cpu::add).  We don't generate methods (TODO: do this"
Edward Yang,ezyang@fb.com,2021-03-02 14:05:21,tools/codegen/dest/register_dispatch_key.py,# TODO: dedup this branch
Edward Yang,ezyang@fb.com,2021-04-12 10:11:57,tools/codegen/dest/register_dispatch_key.py,# TODO: Stop hardcoding that the output type is a Tensor.  Note
Edward Yang,ezyang@fb.com,2021-03-02 14:05:21,tools/codegen/dest/register_dispatch_key.py,# TODO: https://github.com/pytorch/pytorch/issues/53023
Edward Yang,ezyang@fb.com,2021-03-02 14:05:21,tools/codegen/dest/register_dispatch_key.py,# TODO: I think this means structured won't work with method
Edward Yang,ezyang@fb.com,2021-04-12 10:11:57,tools/codegen/dest/register_dispatch_key.py,# TODO: Do this in translate instead
Peter Bell,peterbell10@live.co.uk,2021-12-15 14:24:18,tools/codegen/gen.py,# TODO: for ops with structured_delegate it should check the dispatch table of
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/gen.py,# TODO: This was historically used to help some JIT interop code
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/gen.py,"# TODO: Get rid of dynamic_type, after getting tools/autograd"
Edward Yang,ezyang@fb.com,2020-10-29 14:31:56,tools/codegen/gen.py,# TODO: What exactly is the semantics of the 'dispatch' field?
Brian Hirsh,hirsheybar@fb.com,2021-04-21 19:35:09,tools/codegen/gen.py,# TODO: how come ValuesView isn't a Sequence lol
Peter Bell,peterbell10@live.co.uk,2021-11-03 13:17:49,tools/codegen/gen.py,# TODO: --op_registration_whitelist will be removed when all call-sites
Brian Hirsh,hirsheybar@fb.com,2021-05-17 12:21:27,tools/codegen/gen_backend_stubs.py,# TODO: allow structured external backends later.
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/gen_lazy_tensor.py,TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
Will Constable,whc@fb.com,2021-12-02 07:48:20,tools/codegen/gen_lazy_tensor.py,"TODO(alanwaketan): Once all ops are grouped properly, we should no longer need this hack."
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/model.py,# TODO: figure out what this does
Edward Yang,ezyang@fb.com,2020-11-17 15:23:03,tools/codegen/model.py,# TODO: probably better to accumulate these errors and report them all
Brian Hirsh,hirsheybar@fb.com,2021-07-08 14:30:32,tools/codegen/model.py,# TODO: This discrepancy isn't required; we could also generated
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/model.py,# TODO: Need to handle collisions with argument names at some point
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/model.py,# TODO: fixme
Elias Ellison,eellison@devfair044.h1.fair,2021-11-09 18:31:17,tools/codegen/model.py,# TODO: im not good enough with regexes to ignore -> *
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/model.py,"'ConstQuantizerPtr',  # TODO: rename"
Edward Yang,ezyang@fb.com,2020-08-31 08:58:32,tools/codegen/model.py,# TODO: deduplicate annotation matching with Return
Edward Yang,ezyang@fb.com,2020-12-02 07:47:13,tools/codegen/model.py,# TODO: Use a real parser here; this will get bamboozled
Edward Yang,ezyang@fb.com,2020-12-02 07:47:13,tools/codegen/model.py,# TODO: These invariants are weirdly asymmetric?
Edward Yang,ezyang@fb.com,2020-12-02 07:47:13,tools/codegen/model.py,# TODO: Fancier types?
Chen Lai,chenlai@fb.com,2021-12-16 10:28:10,tools/codegen/operator_versions/gen_mobile_upgraders.py,# TODO: remove the skip after these two operators schemas are fixed
Chen Lai,chenlai@fb.com,2021-12-16 10:28:10,tools/codegen/operator_versions/gen_mobile_upgraders.py,# TODO: remove the skip after these two operators schemas are fixed
Jiakai Liu,liujiakai@fb.com,2020-11-19 21:44:43,tools/codegen/utils.py,# TODO: Use a real parser here; this will get bamboozled
Edward Yang,ezyang@fb.com,2021-02-04 09:10:34,tools/codegen/utils.py,# TODO: this does the wrong thing with KeyError
Brian Hirsh,hirsheybar@fb.com,2021-10-28 10:43:11,tools/codegen/utils.py,"# TODO: put this somewhere else, maybe"
Brian Hirsh,hirsheybar@fb.com,2021-10-28 10:43:11,tools/codegen/utils.py,# TODO: Update the comment reference to the correct location
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2021-05-14 01:52:38,tools/coverage_plugins_package/src/coverage_plugins/jit_plugin.py,# TODO: Because torch.jit._IgnoreContextManager relies on Python's `exec` method
Thomas Viehmann,tv@beamnet.de,2019-01-29 11:19:51,tools/pyi/gen_pyi.py,"# TODO: Consider defining some aliases for our Union[...] types, to make"
Jon Malmaud,malmaud@gmail.com,2019-07-01 09:41:50,tools/pyi/gen_pyi.py,# TODO make these types more precise
Brian Hirsh,hirsheybar@fb.com,2020-12-07 10:37:38,tools/pyi/gen_pyi.py,# TODO: we should probably add them in
Thomas Viehmann,tv@beamnet.de,2019-01-29 11:19:51,tools/pyi/gen_pyi.py,# TODO: Missing type hints for nn
Thomas Viehmann,tv@beamnet.de,2019-01-29 11:19:51,tools/pyi/gen_pyi.py,"# TODO: These are deprecated, maybe we shouldn't type hint them"
Thomas Viehmann,tv@beamnet.de,2019-01-29 11:19:51,tools/pyi/gen_pyi.py,# TODO: don't explicitly list dtypes here; get it from canonical
Edward Z. Yang,ezyang@mit.edu,2018-01-16 09:32:22,tools/setup_helpers/generate_code.py,"# TODO: This is a little inaccurate, because it will also pick"
Edward Yang,ezyang@fb.com,2020-03-29 19:46:19,aten/src/ATen/common_with_cwrap.py,"# TODO: Uggggh, parsing the schema string here, really???"
Trevor Killeen,killeentm@gmail.com,2017-06-09 13:53:27,aten/src/aten/common_with_cwrap.py,# TODO(zach): why does cwrap not propagate 'name'? I need it
Trevor Killeen,killeentm@gmail.com,2017-06-09 13:53:27,aten/src/aten/common_with_cwrap.py,# TODO(zach): added option to remove keyword handling for C++ which cannot
Jane Xu,janeyx@fb.com,2021-03-02 07:33:57,torch/testing/_internal/print_test_stats.py,# TODO: consolidate this with the get_cases function from
Jiakai Liu,liujiakai@fb.com,2020-06-16 21:23:24,.circleci/scripts/upload_binary_size_to_scuba.py,# TODO: create dedicated columns
davidriazati@fb.com,davidriazati@fb.com,2021-05-10 14:35:58,tools/test/test_actions_local_runner.py,# TODO: See https://github.com/pytorch/pytorch/issues/57967
Rong Rong (AI Infra),rongr@fb.com,2021-07-06 09:04:49,tools/testing/test_selections.py,# TODO Refactor this and unify with tools.stats.export_slow_tests
Edward Yang,ezyang@fb.com,2019-04-09 11:09:31,torch/__config__.py,"# TODO: In principle, we could provide more structured version/config"
Will Constable,whc@fb.com,2021-01-28 19:27:29,torch/__init__.py,# TODO(torch_deploy) figure out how to freeze version.py in fbcode build
Michael Suo,suo@fb.com,2021-10-28 22:31:25,torch/_deploy.py,"# TODO: Once we decide to break serialization FC, we can"
Michael Suo,suo@fb.com,2021-10-28 22:31:25,torch/_deploy.py,"# TODO: Once we decide to break serialization FC, we can"
Elias Ellison,eellison@fb.com,2019-08-20 16:45:55,torch/_jit_internal.py,# TODO: __name__ not set for submodules in recursive script
Lillian Johnson,lillianjohnson@fb.com,2020-10-20 16:43:25,torch/_jit_internal.py,# TODO support future
Pearu Peterson,pearu.peterson@gmail.com,2021-10-18 11:05:47,torch/_masked/__init__.py,# TODO: What follows is a reference implementation of a masked sum
Pearu Peterson,pearu.peterson@gmail.com,2021-12-01 19:17:33,torch/_masked/__init__.py,# TODO: replace torch.subtract/divide/square/maximum with
Pearu Peterson,pearu.peterson@gmail.com,2021-12-01 10:43:55,torch/_masked/__init__.py,# TODO: replace torch.maximum with masked maximum when available.
Pearu Peterson,pearu.peterson@gmail.com,2021-12-01 10:43:55,torch/_masked/__init__.py,# TODO: eliminate mask_input as unnecessary when using masked divide.
Pearu Peterson,pearu.peterson@gmail.com,2021-12-01 10:43:55,torch/_masked/__init__.py,# TODO: replace torch.divide with masked divide when available.
Edward Yang,ezyang@fb.com,2021-03-29 08:34:19,torch/_tensor.py,"# TODO: skipping storage copy is wrong for meta, as meta"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/_tensor.py,"# TODO: Once we decide to break serialization FC, no longer"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/_tensor.py,"# TODO: Once we decide to break serialization FC, no longer"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/_tensor.py,"# TODO: Once we decide to break serialization FC, no longer"
Rong Rong,rongr@fb.com,2020-09-24 08:20:06,torch/tensor.py,"# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185"
Rong Rong,rongr@fb.com,2020-09-24 08:20:06,torch/tensor.py,"# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185"
Rong Rong,rongr@fb.com,2020-09-24 08:20:06,torch/tensor.py,"# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185"
Rong Rong,rongr@fb.com,2020-09-24 08:20:06,torch/tensor.py,"# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185"
albanD,desmaison.alban@gmail.com,2020-12-22 12:07:00,torch/_tensor_str.py,# TODO(albanD) This needs to be updated when more than one level is supported
anjali411,chourdiaanjali123@gmail.com,2020-05-11 19:57:31,torch/_tensor_str.py,# TODO: add an API to map real -> complex dtypes
Edward Yang,ezyang@fb.com,2020-06-22 09:16:41,torch/_tensor_str.py,# TODO: This implies that ellipses is valid syntax for allocating
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/_utils.py,"# TODO: Once we decide to break serialization FC, `storage` no longer needs to"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/_utils.py,"# TODO: Once we decide to break serialization FC, `storage` no longer needs to"
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/dynamic/linear.py,# TODO: Need to add options to qconfig to avoid the calibration.
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/dynamic/linear.py,# TODO: Add calibration for the sparsity
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/dynamic/linear.py,# TODO (zaf): Mask might not be part of the qconfig (T83295194)
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,# TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,"# TODO: We will save the original weight and bias, because the unpacking is not yet there."
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,# TODO: The unpacking is not yet implemented
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,# TODO (zaf): Inherit from `quantized.Linear` (T83294430)
Zafar,cc.rafaz@zafar.cc,2021-12-09 02:57:31,torch/ao/nn/sparse/quantized/linear.py,TODO(zaf): Need to add the sparse params to the qconfig
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,# TODO: Need to add options to qconfig to avoid the calibration.
Zafar Takhirov,zaf@fb.com,2021-04-22 14:06:13,torch/ao/nn/sparse/quantized/linear.py,# TODO: Add calibration for the sparsity
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): expose these
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): do not observe nodes we do not care
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): expose these
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): better check when scripted
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): align on naming
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-12 11:59:44,torch/ao/ns/_numeric_suite_fx.py,# TODO(future PR): expose these
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-25 22:27:30,torch/quantization/ns/graph_matcher.py,# TODO(next): make this code handle matching by what is before the base op
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-25 22:27:30,torch/quantization/ns/graph_matcher.py,# TODO(future PR): check for matches start_op_node and base_op_node
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/graph_passes.py,"# TODO(future PR): determine the actual dtype of node_c,"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-06-30 08:07:04,torch/quantization/ns/graph_passes.py,# TODO(future PR): add handling for quantize_per_tensor
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/graph_passes.py,# TODO(future PR): look into using copy_node API instead
Vasiliy Kuznetsov,vasiliy@fb.com,2021-02-18 08:14:57,torch/quantization/ns/graph_passes.py,TODO(before land): real docblock
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-25 22:27:30,torch/quantization/ns/graph_passes.py,# TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-02 09:31:08,torch/quantization/ns/graph_passes.py,# TODO: explain this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/mappings.py,# TODO(future PR): clean this up
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/mappings.py,# TODO(future PR): implement shadowing for binary ops and
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/mappings.py,# TODO(future PR): implement shadowing for binary ops and
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-14 08:59:38,torch/quantization/ns/ns_types.py,# TODO(future PR): see if we can use typing_extensions's TypedDict instead
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,torch/quantization/ns/pattern_utils.py,# TODO(future PR): allow customizations
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,torch/quantization/ns/pattern_utils.py,# TODO(future PR): reuse existing quantization mappings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,torch/quantization/ns/pattern_utils.py,# TODO(future PR): add the rest of modules and ops here
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-15 16:01:22,torch/quantization/ns/pattern_utils.py,# TODO(future PR): allow customizations from default patterns.
Vasiliy Kuznetsov,vasiliy@fb.com,2021-07-17 20:50:50,torch/quantization/ns/pattern_utils.py,"# TODO(future PR): if needed, implement matching for a node"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-02 09:31:08,torch/quantization/ns/utils.py,# TODO(future PR): consider deleting this enum and using the torch types
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-16 10:28:31,torch/quantization/ns/utils.py,"# TODO(future PR): while these functions can support multiple dtypes,"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-02-16 19:57:24,torch/quantization/ns/utils.py,"# TODO(future PRs): dynamic quant, fake quant, etc"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-04-27 16:26:26,torch/quantization/ns/utils.py,# TODO(future PR): clean this up
Vasiliy Kuznetsov,vasiliy@fb.com,2021-06-30 08:07:04,torch/quantization/ns/utils.py,# TODO(future PR): handle more functionals
Vasiliy Kuznetsov,vasiliy@fb.com,2021-06-30 08:07:04,torch/quantization/ns/utils.py,# TODO(future PR): handle functional ops which inherit qparams from input
Charles David Hernandez,cdhernandez@fb.com,2021-08-12 20:57:54,torch/quantization/ns/utils.py,# TODO(future PR): use relationship map instead of hardcoding
Vasiliy Kuznetsov,vasiliy@fb.com,2021-03-12 09:53:02,torch/quantization/ns/weight_utils.py,"# TODO(future PR): make more generic, handle everything"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-07-23 09:03:49,torch/quantization/ns/weight_utils.py,# TODO(future PR): why does packed_weight.unpack() not work?
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO(future PR): clean this up
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO: is this right? Don't really understand this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO(future PR): add other math overrides
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO(future PR): add inputs io hook
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO(future PR): handle more dtypes
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO: is this right? Don't really understand this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# before hooks (TODO)
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace.py,# TODO(future PR): handle more dtypes
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,"# TODO: this is not handling non-tensor tuple args (for example,"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO(future PR): handle other output types
Vasiliy Kuznetsov,vasiliy@fb.com,2021-12-21 06:21:59,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO(future PR): move this into mappings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO use arg_dequant_infos
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO move op-specific logic out of here
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO: handle fqn
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO use arg_dequant_infos
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO(future): remove the hack
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/auto_trace_rewriter.py,# TODO(future PR): handle cases where the module is not symbolically
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/fusion.py,TODO: test coverage
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/mappings.py,# TODO(future PR): reuse all of these with existing quantization mappings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/mappings.py,# TODO: enforce that functions in fp32_to_int8_fun_mapping must both be
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,torch/ao/quantization/_dbr/mappings.py,# TODO(future PR): enable DBR quantization for embeddings
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/mappings.py,# TODO: better name
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/mappings.py,# TODO(future): reuse global mapping
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-21 07:04:51,torch/ao/quantization/_dbr/mappings.py,# TODO(future PR): reuse global mapping
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/mappings.py,# TODO: move these out
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/model_utils.py,# TODO: create weight observers from qconfig.weight
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/model_utils.py,# TODO: delete the original weights
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/model_utils.py,# TODO: create weight observers from qconfig.weight
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/model_utils.py,# TODO: delete the original weights
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-05 06:31:10,torch/ao/quantization/_dbr/module_swap_utils.py,# TODO(future PR): add support for other dtypes
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): maybe better name
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): add serialization support
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): include kwargs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): handle types which are not torch.Tensor
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): use the Logger class and allow user overrides of it
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/quantization_state.py,"Callable,  # fp32 op type (TODO future PR: add quantized op type)"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO: do not run this twice on input and output
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): other output types
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO generalize this for more things
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-21 07:04:51,torch/ao/quantization/_dbr/quantization_state.py,# TODO: refactor this to use iterate_and_apply
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-21 07:04:51,torch/ao/quantization/_dbr/quantization_state.py,# TODO: handle non-tensor inputs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-21 07:04:51,torch/ao/quantization/_dbr/quantization_state.py,# TODO: handle non-tensor inputs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-21 07:04:51,torch/ao/quantization/_dbr/quantization_state.py,"# TODO: this is not handling non-tensor tuple args (for example,"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO move op-specific logic out of here
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO move op-specific logic out of here
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,"TODO: add dequant, if needed"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,"# TODO: instead of always doing this if there is an observer,"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO: use actual dtype instead of defaulting to float
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): add an observer if needed
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO: handle objects with deeper nested tensors
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO: handle other tuple subclasses more generically
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,"# hacky check for collections.namedtuple, TODO improve this"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(next): fix this for torch.cat
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): check if _qtensor_id needs to become an actual
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): handle non-tensor outputs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-12-17 05:56:40,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): respect qconfig for torch.cat
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,"# TODO(future PR): this assumes current dtype is quint8,"
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): currently this only handles float32 and
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): check qconfig is None
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO: make this handle more cases
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO: handle module -> add_scalar -> add_scalar
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO: the following line needs to only check fqn
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): refactor to avoid this.
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future PR): check qconfig is None
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/quantization_state.py,# TODO(future): remove the hack
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/utils.py,# TODO: fix lint
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/utils.py,# TODO(future PR): verify correctness of this for all
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-06 13:21:54,torch/ao/quantization/_dbr/utils.py,# TODO(future PR): extend to the rest of the container classes
Vasiliy Kuznetsov,vasiliy@fb.com,2022-01-24 06:19:45,torch/ao/quantization/_dbr/utils.py,# TODO(before land): do we still need this branch?
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_dbr/utils.py,# TODO(future PR): handle RNNs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/utils.py,TODO(future PR): figure out why is_quantized returns False for
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-20 15:13:56,torch/ao/quantization/_dbr/utils.py,# TODO: return this to the caller
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_quantize_dbr.py,TODO(future PR): better docblock
Vasiliy Kuznetsov,vasiliy@fb.com,2021-12-17 05:56:40,torch/ao/quantization/_quantize_dbr.py,# TODO(future PR): QAT support
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_quantize_dbr.py,# TODO(future PR): clean this up and align with other APIs
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_quantize_dbr.py,"# TODO write up issue, maybe fix"
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_quantize_dbr.py,# TODO: fix LSTM handling in eager mode static quant and remove this
Vasiliy Kuznetsov,vasiliy@fb.com,2021-11-11 06:22:43,torch/ao/quantization/_quantize_dbr.py,TODO(future PR): better docblock
Jerry Zhang,jerryzh@fb.com,2021-10-20 18:53:14,torch/ao/quantization/fx/_convert_new.py,# TODO: support dynamic quant
Jerry Zhang,jerryzh@fb.com,2021-10-20 18:53:14,torch/ao/quantization/fx/_convert_new.py,# TODO: maybe need more complex attr name here
Jerry Zhang,jerryzh@fb.com,2021-12-30 12:29:32,torch/ao/quantization/fx/_convert_do_not_use.py,# TODO: move this to a separate function
Jerry Zhang,jerryzh@fb.com,2021-12-30 12:29:32,torch/ao/quantization/fx/_convert_do_not_use.py,# TODO: allow convert_custom_config_dict to override backend_config_dict
Jerry Zhang,jerryzh@fb.com,2021-11-02 19:20:23,torch/ao/quantization/fx/_convert_do_not_use.py,# TODO: refactor this part to a function
Jerry Zhang,jerryzh@fb.com,2021-10-20 19:11:54,torch/ao/quantization/fx/_convert_new.py,# TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
Jerry Zhang,jerryzh@fb.com,2021-11-22 21:33:38,torch/ao/quantization/fx/_convert_do_not_use.py,# TODO: may need to change the mapping when we support dynamic quantization
Jerry Zhang,jerryzh@fb.com,2021-10-18 13:10:26,torch/ao/quantization/fx/_lower_to_native_backend.py,# TODO: maybe orgnize this better (e.g. break down to more functions)
Jerry Zhang,jerryzh@fb.com,2021-11-19 13:17:50,torch/ao/quantization/fx/backend_config_dict/__init__.py,# TODO: add more validations
Jerry Zhang,jerryzh@fb.com,2021-12-16 17:08:31,torch/ao/quantization/fx/backend_config_dict/fuse_handler.py,# TODO: move DefaultFuseHandler
Jerry Zhang,jerryzh@fb.com,2021-11-19 13:17:50,torch/ao/quantization/fx/backend_config_dict/tensorrt.py,TODO: add a README when it's more stable
Jerry Zhang,jerryzh@fb.com,2021-11-02 19:20:23,torch/ao/quantization/fx/backend_config_dict/tensorrt.py,"# TODO: maybe make ""pattern"" to be a list of patterns"
Jerry Zhang,jerryzh@fb.com,2021-11-02 19:20:23,torch/ao/quantization/fx/backend_config_dict/tensorrt.py,"# TODO: current patterns are the ones after fusion, we will want to expose fusion"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/convert.py,# TODO this should be removed now that gpu support for quantization is being supported.
Supriya Rao,supriyar@fb.com,2021-10-22 21:12:18,torch/ao/quantization/fx/convert.py,# TODO refactor this code once we update the prepare logic to have additional information on
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/convert.py,# TODO: we may want to try to remove the special case here
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/convert.py,# TODO: need to extend this to consider all relevant args instead of just arg[0]
Jerry Zhang,jerryzh@fb.com,2021-12-07 16:10:51,torch/ao/quantization/fx/fuse.py,"# TODO: currently we hard code the root node, which only works for"
Jerry Zhang,jerryzh@fb.com,2021-12-07 16:10:51,torch/ao/quantization/fx/fusion_patterns.py,# TODO: change the signature for fuser_method to take matched module patterns
Jerry Zhang,jerryzh@fb.com,2021-12-16 15:00:48,torch/ao/quantization/fx/fusion_patterns.py,# TODO: maybe add a pass to cleanup bn modules?
Jerry Zhang,jerryzh@fb.com,2021-12-07 16:10:51,torch/ao/quantization/fx/match_utils.py,# TODO: maybe rename this to MatchInputNode
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/pattern_utils.py,# TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
Jerry Zhang,jerryzh@fb.com,2021-10-27 22:08:26,torch/ao/quantization/fx/prepare.py,# TODO: support check for standalone module
Jerry Zhang,jerryzh@fb.com,2021-12-16 17:08:31,torch/ao/quantization/fx/prepare.py,"# TODO: this only checks one input and one output, need to generalize to multiple"
Jerry Zhang,jerryzh@fb.com,2021-12-22 21:14:56,torch/ao/quantization/fx/prepare.py,# TODO: sm_backend_config_dict can fallback to use parent's backend_config_dict
Jerry Zhang,jerryzh@fb.com,2021-11-17 11:18:06,torch/ao/quantization/fx/prepare.py,"# TODO: remove observed_op, looks like it's not used"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,"TODO(future PR, if needed): explicitly spell out the non-Tensor"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): consider stopping matching getitem
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): change this so a placeholder is inserted for
Jerry Zhang,jerryzh@fb.com,2021-11-17 11:18:06,torch/ao/quantization/fx/prepare.py,# TODO: this is looking into how the value is used in the future
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): move the following logic to
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): update the output_quantized_idxs API to match
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,"# TODO(future PR): support more dtypes in model outputs, if necessary"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): see if we need to allow specifying qconfig
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): delete the orphaned observer modules
Jerry Zhang,jerryzh@fb.com,2021-11-17 11:18:06,torch/ao/quantization/fx/prepare.py,# TODO: rename this to node_name_to_target_dtype_info
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO(future PR): consider stopping matching getitem
Jerry Zhang,jerryzh@fb.com,2021-11-19 13:17:50,torch/ao/quantization/fx/prepare.py,# TODO: make WEIGHT_INDEX_DICT and BIAS_INDEX_DICT an argument to the functions that needs them
Jerry Zhang,jerryzh@fb.com,2021-11-19 13:17:50,torch/ao/quantization/fx/prepare.py,# TODO: refactor this part to return WEIGHT_INDEX_DICT and BIAS_INDEX_DICT
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/prepare.py,# TODO: support regex as well
Jerry Zhang,jerryzh@fb.com,2021-12-22 21:14:56,torch/ao/quantization/fx/qconfig_utils.py,# TODO: rename this file to config_utils
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO(future PR): potentially clean up and deduplicate these
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"TODO: This is fragile, whether output is quantized should not depend on `is_reference` since"
Ha-nyung Chung,hanyung@fb.com,2021-12-09 21:53:22,torch/ao/quantization/fx/quantization_patterns.py,"# TODO (refactor) this is duplicated, maybe have a helper function"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: add qat.Conv1d
Andrew Or,andrewor@fb.com,2021-12-14 11:16:59,torch/ao/quantization/fx/quantization_patterns.py,# TODO: rename Relu -> ReLU to be more consistent with other classes
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: is_reference option for conv module
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# hardcoded for now, TODO: expose the api to user,"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# TODO: may need to change the key to Node regenerate the map in each transformation,"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: include the configuration in backend_config_dict
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: the name should be weight is int8 quantized
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# TODO: may need to change the key to Node regenerate the map in each transformation,"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# TODO: may need to change the key to Node regenerate the map in each transformation,"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# TODO (refactor) this is duplicated, maybe have a helper function"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO (maybe): merge with embedding quantize handler
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# TODO: make helper functions for (torch.quint8, torch.qint8, None)"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,TODO: maybe rename this to TensorValueOpQuantizeHandler
Jerry Zhang,jerryzh@fb.com,2021-10-18 11:04:14,torch/ao/quantization/fx/quantization_patterns.py,# TODO: remove special case for operator.getitem
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,"# hardcoded for now, TODO: expose the api to user,"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: include the configuration in backend_config_dict
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_patterns.py,# TODO: enable later
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/quantization_types.py,# TODO(future PR): improve this.
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/utils.py,"# TODO: it's not used, so actually we can skip quantization"
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/utils.py,# TODO(future PR): remove this entire function  and
Jerry Zhang,jerryzh@fb.com,2021-09-22 09:27:42,torch/ao/quantization/fx/utils.py,# TODO(future PR): remove this entire function  and
Charles David Hernandez,cdhernandez@fb.com,2021-09-16 10:31:21,torch/ao/quantization/observer.py,# TODO: switch to scale.item() after adding JIT support
Charles David Hernandez,cdhernandez@fb.com,2021-09-16 10:31:21,torch/ao/quantization/observer.py,# TODO: switch to zero_point.item() after adding JIT support
andrewor,andrewor@devvm1047.frc0.facebook.com,2021-11-23 15:20:52,torch/ao/quantization/observer.py,# TODO(future PR): remove these defaults and enforce activation functions
Jerry Zhang,jerryzh@fb.com,2021-12-17 22:29:40,torch/ao/quantization/qconfig.py,# TODO: remove QConfigAny and replace it with Optional[QConfig]
Charles David Hernandez,cdhernandez@fb.com,2021-09-16 12:55:55,torch/ao/quantization/quantization_mappings.py,# TODO: merge with default static mapping
Charles David Hernandez,cdhernandez@fb.com,2021-09-16 12:55:55,torch/ao/quantization/quantization_mappings.py,# TODO: merge with get_static_quant_module_class
Terry Chen,terrychen@fb.com,2022-01-21 15:58:11,torch/ao/quantization/quantize.py,# TODO remove Dropout special after codebase stable
Zafar Takhirov,zaf@fb.com,2021-09-08 04:57:28,torch/ao/quantization/quantize.py,# TODO: These are the modules that cannot be observed
Zafar Takhirov,zaf@fb.com,2021-09-08 04:57:28,torch/ao/quantization/quantize.py,# TODO: remove allow_list
Zafar Takhirov,zaf@fb.com,2021-09-08 04:57:28,torch/ao/quantization/quantize.py,# TODO: maybe we should change activation_post_process to _activation_post_process
Zafar Takhirov,zaf@fb.com,2021-09-08 04:57:28,torch/ao/quantization/quantize.py,# TODO: rename to something more general
Vasiliy Kuznetsov,vasiliy@fb.com,2021-10-11 18:43:45,torch/ao/quantization/quantize_fx.py,"# TODO(future PR): potentially support multiple indices ('0,1') and/or"
Jerry Zhang,jerryzh@fb.com,2021-12-22 21:14:56,torch/ao/quantization/quantize_fx.py,"{}  # backend_config_dict, TODO: point to README doc when it's ready"
Jerry Zhang,jerryzh@fb.com,2021-12-22 21:14:56,torch/ao/quantization/quantize_fx.py,"{})  # backend_config_dict, TODO: point to README doc when it's ready"
Jerry Zhang,jerryzh@fb.com,2021-12-07 10:58:10,torch/ao/quantization/utils.py,# TODO: not sure if typing supports recursive data types
Karen Zhou,kazhou@fb.com,2021-08-25 09:55:02,torch/ao/sparsity/experimental/pruner/base_pruner.py,self.model = model  # TODO: Need to figure out how to load without this.
Zafar,cc.rafaz@zafar.cc,2021-09-28 14:11:12,torch/ao/sparsity/sparsifier/base_sparsifier.py,"TODO: Need a clean way of loading the state of the ""preapred"" module"
Zafar,cc.rafaz@zafar.cc,2021-07-02 16:27:35,torch/ao/sparsity/sparsifier.py,self.model = model  # TODO: Need to figure out how to load without this.
Zafar,cc.rafaz@zafar.cc,2021-10-01 03:15:48,torch/ao/sparsity/sparsifier/base_sparsifier.py,# TODO: Remove the configuration by reference ('module')
Zafar,cc.rafaz@zafar.cc,2021-07-02 16:27:35,torch/ao/sparsity/sparsifier.py,# TODO: Call the torch.ao.utils.convert in here
Zafar,cc.rafaz@zafar.cc,2021-07-02 17:33:50,torch/ao/sparsity/sparsifier/weight_norm_sparsifier.py,# TODO: Add support for multiple parametrizations for the same weight
jjsjann123,alex.jann2012@gmail.com,2021-10-27 12:09:53,torch/autocast_mode.py,# TODO: support get_autocast_gpu/cpu_dtype
Adam Paszke,adam.paszke@gmail.com,2017-03-30 07:25:32,torch/autograd/_functions/tensor.py,# TODO: deprecate this
albanD,desmaison.alban@gmail.com,2021-06-10 19:26:51,torch/autograd/gradcheck.py,# TODO: handle the other Ju
Jeffrey Wan,jw3468@fb.com,2021-03-24 14:30:58,torch/autograd/gradcheck.py,"# TODO: To cover more problematic cases, replace stride = 0 check with"
Jeffrey Wan,jw3468@fb.com,2021-04-27 07:51:54,torch/autograd/gradcheck.py,# TODO: properly handle case when u is tuple instead of only taking first element
soulitzer,soulitzer@gmail.com,2021-12-14 23:32:28,torch/autograd/gradcheck.py,# TODO: do we want to test this too?
Rohan Varma,rvarm1@fb.com,2020-09-17 18:42:52,torch/autograd/profiler.py,# Stores underlying RecordFunction as a tensor. TODO: move to custom
Zachary DeVito,zdevito@gmail.com,2017-11-16 13:58:09,torch/autograd/profiler.py,thread=0)  # TODO: find in sqlite database
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/prepare.py,# TODO: See if it's possible to use those directly.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/prepare.py,# TODO: See if it's possible to use those directly.
David Reiss,dreiss@fb.com,2021-04-06 13:40:04,torch/backends/_nnapi/prepare.py,# TODO: Maybe make these names match the original.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Add type annotations
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Check tensor types for ops
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Expose these directly to Python to avoid maintaining this list.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Make this an enum.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Support non-equal-rank broadcast where semantics match.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Handle dilation
David Reiss,dreiss@fb.com,2021-04-06 13:40:04,torch/backends/_nnapi/serializer.py,"# TODO: Improve this error message, possibly after converting"
David Reiss,dreiss@fb.com,2021-04-06 13:40:04,torch/backends/_nnapi/serializer.py,# TODO: Possibly check scale and zero point.
David Reiss,dreiss@fb.com,2021-04-06 13:40:04,torch/backends/_nnapi/serializer.py,# TODO: Possibly support variable-sized inputs.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Support this by adding trailing 1 dims.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Validate ceil_mode semantics.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Transform at load time to share weights with CPU model.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Support automatic reshape
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Transform at load time to share weights with CPU model.
David Reiss,dreiss@fb.com,2020-11-05 20:49:56,torch/backends/_nnapi/serializer.py,# TODO: Transform at load time to share weights with CPU model.
Adam Paszke,adam.paszke@gmail.com,2018-06-02 11:55:25,torch/contrib/_tensorboard_vis.py,# TODO: handle attrs
jjsjann123,alex.jann2012@gmail.com,2021-10-27 12:09:53,torch/cpu/amp/autocast_mode.py,# TODO: discuss a unified TorchScript-friendly API for autocast
Will Constable,whc@fb.com,2021-05-20 11:28:08,torch/csrc/deploy/example/generate_examples.py,"# TODO(whc) can this name come from buck somehow,"
Will Constable,whc@fb.com,2021-01-28 19:27:29,torch/cuda/__init__.py,"# TODO(torch_deploy): this accesses linecache, which attempts to read the"
jjsjann123,alex.jann2012@gmail.com,2021-10-27 12:09:53,torch/cuda/amp/autocast_mode.py,# TODO: discuss a unified TorchScript-friendly API for autocast
Michael Carilli,mcarilli@nvidia.com,2020-03-24 08:58:40,torch/cuda/amp/autocast_mode.py,"# TODO:  when python 2 support is dropped, change the signature to"
Michael Carilli,mcarilli@gmail.com,2020-10-01 07:48:56,torch/cuda/amp/grad_scaler.py,# TODO: is there a way to split by device and dtype without appending in the inner loop?
Rohan Varma,rvarm1@fb.com,2021-11-02 23:25:54,torch/distributed/_fsdp/fully_sharded_data_parallel.py,"# TODO: state dict offloading, activation offloading"
Yanli Zhao,yanlizhao@fb.com,2021-12-22 23:01:17,torch/distributed/_fsdp/fully_sharded_data_parallel.py,"# TODO, BACKWARD_PRE_CPU, prefetch full parameters and keep them in the CPU memory"
Rohan Varma,rvarm1@fb.com,2022-01-25 22:51:56,torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py,# TODO: register_fsdp once FSDP supports communication hook.
Yinbin Ma,yinbin@fb.com,2021-08-18 20:52:17,torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py,# TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.
Rohan Varma,rvarm1@fb.com,2022-01-22 15:59:55,torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py,# TODO: Add an example to use such a wrapper.
lezcano,lezcano-93@hotmail.com,2021-05-10 22:55:30,torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py,# TODO Consider using Q = torch.orgqr(*torch.geqrf(A)) to compute the Q of the QR _much_ faster
Yi Wang,wayi@fb.com,2021-02-06 21:20:01,torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py,# TODO: The above procedure does two matmul+allreduce steps per iteration --
Yi Wang,wayi@fb.com,2021-02-06 21:20:01,torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py,# TODO: The above procedure does two matmul+allreduce steps per iteration --
Yi Wang,wayi@fb.com,2021-05-17 16:46:16,torch/distributed/distributed_c10d.py,# TODO: specify __all__
Tongzhou Wang,tongzhou.wang.1994@gmail.com,2018-09-18 10:47:27,torch/distributed/distributed_c10d.py,# TODO: remove them when users are ready to take a hard dependency on PyTorch 1.
Aliaksandr Ivanou,aivanou@fb.com,2021-03-22 23:13:48,torch/distributed/elastic/agent/server/api.py,# TODO @kiuk - make entrypoint a required field
Aliaksandr Ivanou,aivanou@fb.com,2021-03-22 23:13:48,torch/distributed/elastic/agent/server/api.py,"# TODO after stopping workers, wait at least monitor_interval*2 for"
Kiuk Chung,kiuk@fb.com,2021-03-10 12:25:58,torch/distributed/elastic/multiprocessing/api.py,# TODO remove and replace in favor of contextlib.nullcontext
Kiuk Chung,kiuk@fb.com,2021-03-05 11:24:25,torch/distributed/elastic/rendezvous/etcd_rendezvous.py,# TODO: look into using weakref here instead.
Kiuk Chung,kiuk@fb.com,2021-03-05 11:24:25,torch/distributed/elastic/rendezvous/etcd_rendezvous.py,"# TODO: we should probably handle a few additional errors,"
Kiuk Chung,kiuk@fb.com,2021-03-05 11:24:25,torch/distributed/elastic/rendezvous/etcd_rendezvous.py,# TODO: look into using weakref here instead.
Kiuk Chung,kiuk@fb.com,2021-03-05 11:24:25,torch/distributed/elastic/rendezvous/etcd_rendezvous.py,# TODO: implement timeout
Kiuk Chung,kiuk@fb.com,2021-03-05 11:24:25,torch/distributed/elastic/utils/distributed.py,# TODO properly map the exceptions in pybind (c10d/init.cpp)
Yi Wang,wayi@fb.com,2021-06-04 03:41:52,torch/distributed/nn/api/remote_module.py,"# TODO: We need to change this to rpc.remote, and make it async (see the else branch below)."
Yi Wang,wayi@fb.com,2021-05-03 19:09:20,torch/distributed/nn/jit/templates/remote_module_template.py,# TODO: Merge these two templates together in the future once TorchScript syntax is improved.
Wanchao Liang,wanchaol@users.noreply.github.com,2020-09-25 17:02:16,torch/distributed/optim/functional_adagrad.py,"# TODO: no union or any types in TorchScript, make step a scalar tensor instead"
Rohan Varma,rvarm1@fb.com,2021-07-26 11:49:48,torch/distributed/optim/functional_sgd.py,"# TODO: Once step_param interface is robust, refactor step to call"
Wanchao Liang,wanchaol@users.noreply.github.com,2020-09-25 17:02:16,torch/distributed/optim/optimizer.py,# TODO (wanchaol): remove this once we added TorchScript
Wanchao Liang,wanchaol@users.noreply.github.com,2020-10-07 15:08:05,torch/distributed/optim/optimizer.py,# TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
Alisson Gusatti Azzolini,azzolini@fb.com,2019-11-11 12:00:41,torch/distributed/optim/optimizer.py,# TODO: improve error propagation
Andrew Gu,andgu@fb.com,2021-08-02 08:31:56,torch/distributed/optim/zero_redundancy_optimizer.py,# TODO: Manually add `self.param_groups` if using a functional
Pritam Damania,pritam.damania@fb.com,2020-10-22 10:53:07,torch/distributed/_pipeline/sync/skip/skippable.py,# TODO(sublee): Move to above of Skippable class for better read flow.
Pritam Damania,pritam.damania@fb.com,2020-06-16 11:58:38,torch/distributed/rpc/backend_registry.py,# TODO: add try-except and destroy _agent in all processes if any fails.
Wanchao Liang,wanchaol@fb.com,2021-12-14 12:13:05,torch/distributed/_sharded_optim/api.py,# TODO: implement state_dict
Wanchao Liang,wanchaol@fb.com,2021-12-14 12:13:05,torch/distributed/_sharded_optim/api.py,# TODO: implement load_state_dict
Wanchao Liang,wanchaol@fb.com,2021-12-14 12:13:05,torch/distributed/_sharded_optim/api.py,# TODO: implement add_param_group
Wanchao Liang,wanchaol@fb.com,2021-11-17 23:16:51,torch/distributed/_sharded_tensor/api.py,# TODO: make sharding spec a ChunkShardingSpec by inferring from the metadata list.
Wanchao Liang,wanchaol@fb.com,2021-12-02 01:01:13,torch/distributed/_sharded_tensor/api.py,# TODO: make sharding spec a ChunkShardingSpec by inferring from the metadata list.
Wanchao Liang,wanchaol@fb.com,2021-07-29 22:02:49,torch/distributed/_sharding_spec/_internals.py,# TODO: evaluate optimizing this if needed.
Wanchao Liang,wanchaol@fb.com,2021-07-29 22:02:49,torch/distributed/_sharding_spec/_internals.py,# TODO: Can we improve this error message to point out the gaps?
Fritz Obermeyer,fritzo@uber.com,2018-01-28 12:26:23,torch/distributions/constraint_registry.py,# TODO define a bijection for LowerCholeskyTransform
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-14 13:52:28,torch/distributions/kl.py,# TODO: Add Beta-Laplace KL Divergence
gabloa,gl2480@columbia.edu,2020-03-12 11:43:58,torch/distributions/kl.py,# TODO: Add ContinuousBernoulli-Laplace KL Divergence
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-14 13:52:28,torch/distributions/kl.py,# TODO: Add Exponential-Laplace KL Divergence
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-14 13:52:28,torch/distributions/kl.py,# TODO: Add Gamma-Laplace KL Divergence
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-14 13:52:28,torch/distributions/kl.py,# TODO: Add Gumbel-Laplace KL Divergence
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-20 12:47:11,torch/distributions/kl.py,# TODO: Add Pareto-Laplace KL Divergence
Vishwak Srinivasan,cs15btech11043@iith.ac.in,2018-01-14 13:52:28,torch/distributions/kl.py,# TODO: Uniform-Laplace KL Divergence
gchanan,gregchanan@gmail.com,2018-01-23 14:15:59,torch/distributions/laplace.py,"# TODO: If we ever implement tensor.nextafter, below is what we want ideally."
Fritz Obermeyer,fritz.obermeyer@gmail.com,2018-01-04 14:58:26,torch/distributions/uniform.py,"# TODO allow (loc,scale) parameterization to allow independent constraints."
Fritz Obermeyer,fritz.obermeyer@gmail.com,2020-12-03 02:40:23,torch/functional.py,# TODO Movie this to C++ once the jit has better support for torch.Size.
Saketh Are,saketh@fb.com,2021-10-21 16:03:51,torch/functional.py,# TODO: figure out how to return torch.return_types.histogramdd
Tongzhou Wang,tongzhou.wang.1994@gmail.com,2018-07-17 10:54:03,torch/functional.py,"# TODO: after having proper ways to map Python strings to ATen Enum, move"
Ralf Gommers,ralf.gommers@gmail.com,2020-08-26 08:23:51,torch/functional.py,# TODO: type dim as BroadcastingList when
Shen Li,shenli@fb.com,2021-08-12 11:39:31,torch/functional.py,_dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
Elias Ellison,eellison@fb.com,2020-03-05 14:42:56,torch/functional.py,# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
James Reed,jamesreed@fb.com,2021-05-14 14:05:44,torch/fx/symbolic_trace.py,# TODO: binary search
James Reed,jamesreed@fb.com,2020-10-07 21:32:51,torch/fx/symbolic_trace.py,# TODO: type annotations for *args and **kwargs
Wang Xu,scottxu0730@gmail.com,2020-10-28 21:07:45,torch/fx/experimental/Partitioner.py,# TODO: add different size support for sparse_nn_partition
Shiyan Deng,dsy842974287@fb.com,2021-08-19 10:16:26,torch/fx/experimental/fx2trt/converters/acc_ops_converters.py,# TODO: Need to benchmark the performance of lowering linear as fully_connected versus
Shiyan Deng,dsy842974287@fb.com,2021-06-02 15:21:00,torch/fx/experimental/fx2trt/converters/linear.py,TODO: We can optimize this to get rid of unneccesary transformation.
Shirong Wu,shirong@fb.com,2021-12-14 12:58:46,torch/fx/experimental/fx2trt/lower.py,TODO: @kefeilu: this function's body should be moved into the actual calling
Shirong Wu,shirong@fb.com,2021-12-14 12:58:46,torch/fx/experimental/fx2trt/lower.py,# TODO: @kefeilu: also incorporates a validator to do inference (and optionally)
Marat Subkhankulov,msubkhankulov@fb.com,2021-12-06 12:03:47,torch/fx/experimental/fx2trt/passes/fuse_pass.py,# TODO: verify that weight comply with TRT structured sparsity requirements:
Shirong Wu,shirong@fb.com,2021-12-14 12:58:46,torch/fx/experimental/fx2trt/split.py,TODO: refactor so we don't set inputs onto the subgraphs
Shiyan Deng,dsy842974287@fb.com,2021-08-15 11:52:20,torch/fx/experimental/fx_acc/acc_tracer.py,# TODO: Move orelse to the body after calling ConditionalExceptionWrapper.
Zeina Migeed,migeedz@fb.com,2021-08-09 11:45:34,torch/fx/experimental/graph_gradual_typechecker.py,# TODO. We leave it like this till we add a type to represent tensor sizes
Meghan Lele,meghanl@fb.com,2021-01-06 21:46:56,torch/fx/experimental/merge_matmul.py,"# TODO: Properly handle aliasing caused by get_attr. For now,"
Horace He,horacehe2007@yahoo.com,2021-03-31 10:13:28,torch/fx/experimental/optimization.py,# TODO: Determine whether this can be removed after type inference.
James Reed,jamesreed@fb.com,2021-03-17 20:39:16,torch/fx/experimental/schema_type_annotation.py,# TODO: can we emit the union of these? What are the implications on TorchScript
James Reed,jamesreed@fb.com,2021-03-17 23:31:48,torch/fx/operator_schemas.py,# TODO: Figure out if this is safe. It seems like when generating the type signatures for
Lillian Johnson,lillianjohnson@fb.com,2020-10-01 20:38:16,torch/fx/experimental/subgraph_creation_example.py,"# TODO currently placeholders/parameters aren't put into random partitions,"
Shiyan Deng,dsy842974287@fb.com,2021-04-24 15:17:47,torch/fx/passes/splitter_base.py,# TODO: this can probably be optimized
Elias Ellison,eellison@fb.com,2020-02-26 18:28:47,torch/jit/_builtins.py,# TODO: add support for more ops
Ansley Ussery,ansley@fb.com,2021-02-12 18:15:57,torch/jit/_check.py,# TODO @ansley: add `Union` once landed
nikithamalgi,nikithamalgi@devvm146.prn0.facebook.com,2021-06-24 10:58:48,torch/jit/_monkeytype_config.py,TODO: To remove this check once Union support lands.
nikithamalgi,nikithamalgi@devvm146.prn0.facebook.com,2021-06-24 10:58:48,torch/jit/_monkeytype_config.py,# TODO: To remove this check once Union suppport in TorchScript lands.
Michael Suo,suo@fb.com,2019-10-12 09:49:56,torch/jit/_recursive.py,# TODO: there should be a more principled way of doing this.
Michael Suo,suo@fb.com,2020-01-29 17:02:38,torch/jit/_recursive.py,"# TODO: We should really error in this case, but its bc-breaking so"
Michael Suo,suo@fb.com,2020-01-29 17:02:38,torch/jit/_recursive.py,"# TODO: We should really error in this case, but its bc-breaking so"
Michael Suo,suo@fb.com,2019-10-12 09:49:56,torch/jit/_recursive.py,"# TODO: could add more detail here. For example, what the user should do"
Michael Suo,suo@fb.com,2019-10-12 09:49:56,torch/jit/_recursive.py,# TODO: Why skip this? Because @torch.jit._overload_method will
Michael Suo,suo@fb.com,2019-10-12 09:49:56,torch/jit/_recursive.py,# TODO: we don't currently do this functions that are recursively
Michael Suo,suo@fb.com,2019-10-12 09:49:56,torch/jit/_recursive.py,points for compilation (TODO add a link when the rules are published).
Michael Suo,suo@fb.com,2020-07-08 11:35:52,torch/jit/_script.py,"# TODO: we don't have _concrete_type set after load(), and in general we lose constant information."
Michael Suo,suo@fb.com,2020-07-08 11:35:52,torch/jit/_script.py,# TODO: it's possible that the following is confusing:
Michael Suo,suo@fb.com,2020-07-05 21:59:08,torch/jit/_script.py,# TODO MAKE SURE THAT DISABLING WORKS
Michael Suo,suo@fb.com,2020-07-09 10:08:10,torch/jit/_serialization.py,# TODO: Pretty sure this approach loses ConstSequential status and such
Michael Suo,suo@fb.com,2020-07-05 21:59:08,torch/jit/_trace.py,# TODO: figure out one liner to .clone() and set requires_grad
Michael Suo,suo@fb.com,2020-07-05 21:59:08,torch/jit/_trace.py,"# TODO: In principle, we track device information in our trace, so it"
Michael Suo,suo@fb.com,2020-07-05 21:59:08,torch/jit/_trace.py,# TODO: Consider adding a utility function to torch.jit to test
Michael Suo,suo@fb.com,2020-07-05 21:59:08,torch/jit/_trace.py,# TODO: I'm not sure if the clone here is necessary but it is safer
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2021-12-02 10:50:25,torch/jit/annotations.py,# TODO: this is hack to recognize NumberType
Ansley Ussery,ansley@fb.com,2021-09-03 06:10:37,torch/jit/annotations.py,# TODO: Determine if the other cases need to be fixed as well
Edward Yang,ezyang@fb.com,2019-03-30 08:58:10,torch/jit/annotations.py,# TODO: Consider not exporting these during wildcard import (reserve
Wanchao Liang,wanchaol@fb.com,2019-11-02 16:37:32,torch/jit/frontend.py,# TODO: proper overriding analysis when implementing class inheritance
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2021-05-14 01:52:38,torch/jit/frontend.py,# TODO: more robust handling of recognizing ignore context manager
Tugsbayasgalan (Tugsuu) Manlaibaatar,tmanlaibaatar@fb.com,2021-05-14 01:52:38,torch/jit/frontend.py,"# TODO: add input, output validator"
Adam Paszke,adam.paszke@gmail.com,2018-02-15 13:53:19,torch/jit/frontend.py,# TODO: try to recover the location of else:? Python doesn't give us useful
James Reed,jamesreed@fb.com,2019-01-15 10:07:18,torch/jit/quantized.py,# TODO: for some reason weak_script_method causes a destruction of the
James Reed,jamesreed@fb.com,2019-01-15 10:07:18,torch/jit/quantized.py,ret = input  # TODO: remove when jit supports exception flow
James Reed,jamesreed@fb.com,2019-05-08 19:44:01,torch/jit/quantized.py,# TODO: support more than just LSTM
Edward Yang,ezyang@fb.com,2018-07-16 15:17:57,torch/multiprocessing/reductions.py,# TODO: Maybe this should be in tensor_classes? :)
David Riazati,davidriazati@fb.com,2018-11-08 01:02:19,torch/nn/_reduction.py,ret = -1  # TODO: remove once JIT exceptions support control flow
Yanan Cao,gmagogsfm@gmail.com,2020-08-01 13:02:20,torch/nn/functional.py,# TODO: Remove this once script supports type() calls
Sameer Deshmukh,sameer.deshmukh93@gmail.com,2020-01-27 08:57:03,torch/nn/functional.py,# TODO: make use of reduce like below when JIT is ready with the missing features:
Basil Hosmer,bhosmer@fb.com,2021-05-11 10:08:37,torch/nn/functional.py,# TODO finish disentangling control flow so we don't do in-projections when statics are passed
Basil Hosmer,bhosmer@fb.com,2021-05-11 10:08:37,torch/nn/functional.py,# TODO finish disentangling control flow so we don't do in-projections when statics are passed
Jerry Zhang,jerryzh@fb.com,2019-08-01 10:03:39,torch/nn/_intrinsic/qat/modules/conv_fused.py,# TODO(jerryzh): extend
Supriya Rao,supriyar@fb.com,2021-08-26 21:05:56,torch/nn/intrinsic/quantized/dynamic/modules/linear_relu.py,# TODO check if we should set reduce_rage = True by default here
Lingyi Liu,lingyiliu@fb.com,2020-03-23 20:32:27,torch/nn/intrinsic/quantized/modules/bn_relu.py,# TODO: Add qat support for BNReLU2d
Lingyi Liu,lingyiliu@fb.com,2020-03-23 20:32:27,torch/nn/intrinsic/quantized/modules/bn_relu.py,# TODO: Add qat support for BNReLU3d
Adam Paszke,adam.paszke@gmail.com,2016-08-19 14:22:47,torch/nn/modules/activation.py,"# TODO: check in THNN (if inplace == True, then assert value <= threshold)"
David Riazati,davidriazati@fb.com,2018-12-04 15:09:30,torch/nn/modules/batchnorm.py,# TODO: if statement only here to tell the jit to skip emitting this when it is None
Joel Schlosser,jbschlosser@fb.com,2021-04-22 16:15:32,torch/nn/modules/conv.py,"padding_mode: str = 'zeros',  # TODO: refine this type"
Joel Schlosser,jbschlosser@fb.com,2021-04-22 16:15:32,torch/nn/modules/conv.py,"padding_mode: str = 'zeros',  # TODO: refine this type"
Tongzhou Wang,tongzhou.wang.1994@gmail.com,2020-01-10 08:13:19,torch/nn/modules/conv.py,# TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/conv.py,# TODO: Conv2dLocal
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/conv.py,# TODO: Conv2dMap
Adam Paszke,adam.paszke@gmail.com,2016-10-09 12:05:24,torch/nn/modules/conv.py,# TODO: ConvTranspose2dMap
Joel Schlosser,jbschlosser@fb.com,2021-04-22 16:15:32,torch/nn/modules/conv.py,"padding_mode: str = 'zeros',  # TODO: refine this type"
Basil Hosmer,bhosmer@fb.com,2021-05-26 15:28:37,torch/nn/modules/linear.py,"# TODO: fail fast on quantization API usage error, then remove this class"
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/linear.py,# TODO: PartialLinear - maybe in sparse?
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/loss.py,# TODO: L1HingeEmbeddingCriterion
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/loss.py,# TODO: MSECriterion weight
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/loss.py,# TODO: ClassSimplexCriterion
Nikita Shulga,nshulga@fb.com,2021-04-09 17:47:06,torch/nn/modules/module.py,# TODO: Remove string escape once Python-3.6 no longer supported
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/normalization.py,# TODO: ContrastiveNorm2d
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/normalization.py,# TODO: DivisiveNorm2d
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/normalization.py,# TODO: SubtractiveNorm2d
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,torch/nn/modules/padding.py,# TODO: grad_output size asserts in THNN
Wanchao Liang,wanchaol@users.noreply.github.com,2019-08-01 17:12:18,torch/nn/modules/rnn.py,# TODO: remove the overriding implementations for LSTM and GRU when TorchScript
David Riazati,davidriazati@fb.com,2018-12-18 17:25:51,torch/nn/modules/rnn.py,ret = input  # TODO: remove when jit supports exception flow
chengjun,chengjun.lu@intel.com,2020-07-07 12:43:19,torch/nn/parallel/comm.py,"# TODO: When `len(inputs) == 1` and all inputs are on `destination`, just"
Eli Stevens,wickedgrey@gmail.com,2017-02-26 11:37:43,torch/nn/parallel/data_parallel.py,# TODO: update notes/cuda.rst when this class handles 8+ GPUs well
Pritam Damania,pritam.damania@fb.com,2021-01-11 16:51:08,torch/nn/parallel/distributed.py,# TODO: Expand to remote RRefs.
Rohan Varma,rvarm1@fb.com,2021-09-22 14:10:07,torch/nn/parallel/distributed.py,# TODO: make DDP uneven inputs context manager support buffer
Rohan Varma,rvarm1@fb.com,2021-08-09 22:27:49,torch/nn/parallel/distributed.py,# TODO: DDPSink is currently enabled for unused parameter detection and
Zafar Takhirov,zaf@fb.com,2021-02-17 12:32:08,torch/nn/quantizable/modules/activation.py,# TODO: This is a potential source of accuracy drop.
Zafar Takhirov,zaf@fb.com,2021-02-17 12:32:08,torch/nn/quantizable/modules/activation.py,# TODO: This method has some duplicate lines with the
Raghuraman Krishnamoorthi,raghuraman@fb.com,2020-06-16 21:23:17,torch/nn/quantized/dynamic/modules/rnn.py,ret = input  # TODO: remove when jit supports exception flow
Jerry Zhang,jerryzh@fb.com,2020-11-17 09:49:47,torch/nn/quantized/modules/batchnorm.py,# TODO: dedup with BatchNorm2d
Jerry Zhang,jerryzh@fb.com,2020-05-05 20:16:35,torch/nn/quantized/modules/conv.py,# TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
Emilio Castillo,ecastill@preferred.jp,2021-09-21 12:38:11,torch/nn/utils/_stateless.py,# TODO allow kwargs such as unsafe and others for parametrization
Jie,jiej@nvidia.com,2020-02-04 09:47:07,torch/nn/utils/memory_format.py,# TODO: expand this to `_ConvNd` when channels_last support is extended
Michela Paganini,micky.91@hotmail.com,2019-11-08 19:35:46,torch/nn/utils/prune.py,# TODO: consider removing this check and allowing users to specify
davidriazati,davidriazati@fb.com,2020-03-02 13:48:06,torch/nn/utils/rnn.py,# TODO: Re-enable this check (.type isn't supported in TorchScript)
Nikita Shulga,nshulga@fb.com,2020-08-14 13:22:34,torch/nn/utils/weight_norm.py,# TODO Make return type more specific
Lara Haidar,haidar.lara@gmail.com,2019-05-10 18:31:15,torch/onnx/symbolic_helper.py,# TODO: remove these once we support Type's in the JIT IR and we can once again
BowenBao,bowbao@microsoft.com,2021-05-27 12:03:59,torch/onnx/symbolic_opset13.py,"# TODO: So far we don""t have a module using this method. We""ll keep"
Gary Miguel,garymiguel@microsoft.com,2021-11-08 14:29:12,torch/onnx/symbolic_opset15.py,#                       TODO: test coverage for mixed types inputs.
Gary Miguel,garymiguel@microsoft.com,2021-11-08 14:29:12,torch/onnx/symbolic_opset15.py,#                       TODO: bfloat16 support.
Gary Miguel,garymiguel@microsoft.com,2021-11-08 14:29:12,torch/onnx/symbolic_opset15.py,#                       TODO: optional start/end attribute.
Edward Z. Yang,ezyang@mit.edu,2017-12-15 10:50:32,torch/onnx/symbolic.py,"# TODO: It would be better to export this as a chunk directly, as this is"
Edward Z. Yang,ezyang@mit.edu,2017-12-15 10:50:32,torch/onnx/symbolic.py,"# TODO: Once we have proper scoping, stop reimplementing chunk, delete this"
Edward Z. Yang,ezyang@fb.com,2017-10-19 13:34:55,torch/onnx/symbolic.py,# TODO: Talk to ONNX about unconditional cast of scalar to float
Negin Raoof,neginmr@utexas.edu,2019-11-04 12:14:18,torch/onnx/symbolic_opset9.py,# TODO: remove this as onnx opset 11 spec allows negative axes
Negin Raoof,neginmr@utexas.edu,2019-11-04 12:14:18,torch/onnx/symbolic_opset9.py,# TODO: remove this as onnx opset 11 spec allows negative axes
Negin Raoof,neginmr@utexas.edu,2019-11-04 12:14:18,torch/onnx/symbolic_opset9.py,# TODO: remove this as onnx opset 11 spec allows negative axes
BowenBao,bowbao@microsoft.com,2019-07-23 16:57:09,torch/onnx/symbolic_opset9.py,"# TODO: If indexing is supported natively in ONNX in future opsets,"
Negin Raoof,neginmr@utexas.edu,2019-11-07 16:53:35,torch/onnx/symbolic_opset9.py,# TODO: Might need a fix in torch group_norm module
BowenBao,bowbao@microsoft.com,2021-07-08 16:16:00,torch/onnx/utils.py,# TODO: can we simplify this to always return a tuple of Tensor or None?
Lara Haidar,haidar.lara@gmail.com,2020-03-29 23:12:32,torch/onnx/utils.py,# TODO: Don't allocate a in-memory string for the protobuf
anderspapitto,anderspapitto@gmail.com,2018-03-08 09:44:16,torch/onnx/utils/__init__.py,# TODO: enable inplace in aten exporting mode.
Negin Raoof,neginmr@utexas.edu,2020-09-30 13:34:26,torch/onnx/utils.py,# TODO: enable inplace in aten exporting mode.
Edward Z. Yang,ezyang@mit.edu,2018-03-16 10:36:11,torch/onnx/utils.py,# TODO: I think this is not necessary anymore
Edward Yang,ezyang@fb.com,2021-10-08 07:37:56,torch/onnx/utils.py,# TODO: https://msdata.visualstudio.com/Vienna/_workitems/edit/1408006
anderspapitto,anderspapitto@gmail.com,2018-03-08 09:44:16,torch/onnx/utils/__init__.py,"# TODO: We might not need this anymore, since most scalars now show up"
Vincent Quenneville-Belair,vincentqb@gmail.com,2021-02-03 17:56:23,torch/optim/_functional.py,# TODO: use foreach API in optim._functional to do all the computation
Michael Suo,suo@fb.com,2021-02-19 10:01:33,torch/package/importer.py,# TODO: I guess we should do copyreg too?
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/package/package_exporter.py,"# TODO: Once we decide to break serialization FC, we can"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/package/package_importer.py,"# TODO: Once we decide to break serialization FC, we can"
Michael Suo,suo@fb.com,2021-02-09 07:34:05,torch/package/importer.py,# TODO from zdevito:
Vasiliy Kuznetsov,vasiliy@fb.com,2021-09-13 15:20:44,torch/quantization/__init__.py,"# TODO(future PR): fix the typo, should be `__all__`"
James Reed,jamesreed@fb.com,2020-10-29 17:01:02,torch/quantization/__init__.py,"# 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx"
Zafar Takhirov,zaf@fb.com,2021-09-15 17:24:09,torch/quantization/fuse_modules.py,# TODO: These functions are not used outside the `fuse_modules.py`
Kurt Mohler,kmohler@quansight.com,2021-11-16 08:41:14,torch/serialization.py,# TODO: This feature could be added in the future
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, this case"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,# TODO: There's an issue here with FC. It might be impossible to
Kurt Mohler,kmohler@quansight.com,2021-11-16 08:41:14,torch/serialization.py,# TODO: This feature could be added in the future
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, this case"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, we can"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, we can"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, we can"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, we can"
Kurt Mohler,kmohler@quansight.com,2021-10-05 13:48:45,torch/serialization.py,"# TODO: Once we decide to break serialization FC, we can"
Philip Meier,github.pmeier@posteo.de,2022-01-12 06:40:45,torch/testing/_comparison.py,# TODO: See https://github.com/pytorch/pytorch/issues/68592
Philip Meier,github.pmeier@posteo.de,2021-11-19 12:33:40,torch/testing/_comparison.py,# TODO: compose all metas into one AssertionError
Philip Meier,github.pmeier@posteo.de,2021-04-07 23:47:38,torch/testing/_core.py,# TODO: implement numpy-like issubdtype
Philip Meier,github.pmeier@posteo.de,2021-04-07 23:47:38,torch/testing/_core.py,# TODO: consider adding torch.unravel_index
Philip Meier,github.pmeier@posteo.de,2021-08-19 12:45:32,torch/testing/_deprecated.py,# TODO: include the deprecation as soon as torch.testing.assert_close is stable
Christian Sarofeen,csarofeen@nvidia.com,2020-05-21 17:15:46,torch/testing/_internal/codegen/random_topo_test.py,# TODO: we should mark
Christian Sarofeen,csarofeen@nvidia.com,2020-05-21 17:15:46,torch/testing/_internal/codegen/random_topo_test.py,# TODO: enable broadcasting when we fully support it.
Peter Bell,peterbell10@live.co.uk,2020-08-06 16:06:38,torch/testing/_internal/common_device_type.py,raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
Rohan Varma,rvarm1@fb.com,2020-03-11 11:24:32,torch/testing/_internal/common_distributed.py,# TODO: we should pipe the exception of the failed subprocess here.
soulitzer,soulitzer@gmail.com,2021-12-14 23:32:28,torch/testing/_internal/common_methods_invocations.py,# TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
anjali411,chourdiaanjali123@gmail.com,2021-06-04 14:11:23,torch/testing/_internal/common_methods_invocations.py,# TODO: Remove the try/except once all operators have sample_inputs_func with
kshitij12345,kshitijkalambarkar@gmail.com,2021-04-07 08:18:56,torch/testing/_internal/common_methods_invocations.py,# TODO: Remove the try/except once all operators have sample_inputs_func with
Heitor Schueroff,heitorschueroff@fb.com,2021-08-26 06:05:28,torch/testing/_internal/common_methods_invocations.py,# TODO(@heitorschueroff) Once all reduction operators are using
Heitor Schueroff,heitorschueroff@fb.com,2021-08-26 06:05:28,torch/testing/_internal/common_methods_invocations.py,# TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
lezcano,lezcano-93@hotmail.com,2022-01-27 10:33:44,torch/testing/_internal/common_methods_invocations.py,# TODO: fix bug in the documentation for svd_lowrank:
Mike Ruberry,mruberry@devfair044.h1.fair,2022-01-24 01:28:07,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME
ankitaS11,ankitalrm@gmail.com,2021-12-02 18:59:37,torch/testing/_internal/common_methods_invocations.py,# TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
Kushashwa Ravi Shrimali,kushashwaravishrimali@gmail.com,2021-11-11 09:15:39,torch/testing/_internal/common_methods_invocations.py,"# TODO: (@krshrimali), add error_inputs_func once https://github.com/pytorch/pytorch/pull/67354 is merged"
Peter Bell,peterbell10@live.co.uk,2021-12-17 09:56:47,torch/testing/_internal/common_methods_invocations.py,"# TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,"
Mike Ruberry,mruberry@devfair044.maas,2021-04-11 20:37:46,torch/testing/_internal/common_methods_invocations.py,# TODO: reconcile with torch.linalg.det and torch.linalg.slogdet
Mike Ruberry,mruberry@devfair044.maas,2021-03-22 03:46:44,torch/testing/_internal/common_methods_invocations.py,# TODO: clamp shares tensors among its sample inputs --- we should prohibit this!
kshitij12345,kshitijkalambarkar@gmail.com,2021-05-29 20:54:15,torch/testing/_internal/common_methods_invocations.py,"# TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,"
kshitij12345,kshitijkalambarkar@gmail.com,2021-05-29 20:54:15,torch/testing/_internal/common_methods_invocations.py,# TODO: Remove this when `make_tensor` supports excluding `0`.
vfdev,vfdev.5@gmail.com,2021-02-02 00:07:44,torch/testing/_internal/common_methods_invocations.py,# TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
albanD,desmaison.alban@gmail.com,2021-04-13 06:17:20,torch/testing/_internal/common_methods_invocations.py,# TODO: update sample inputs with for_inplace_variant kwarg to support this test
albanD,desmaison.alban@gmail.com,2021-04-13 06:17:20,torch/testing/_internal/common_methods_invocations.py,# TODO: update sample inputs with for_inplace_variant kwarg to support this test
Heitor Schueroff,heitorschueroff@fb.com,2021-03-31 20:21:49,torch/testing/_internal/common_methods_invocations.py,# TODO: RuntimeError: cholesky_inverse does not support automatic differentiation for outputs
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: cholesky_inverse throws an error in forward when requires_grad=True
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: jiterator does not support casting to complex outs
Heitor Schueroff,heitorschueroff@fb.com,2021-03-31 20:21:49,torch/testing/_internal/common_methods_invocations.py,"# TODO: RuntimeError: While computing batched gradients,"
Winston Smith,76181208+imaginary-person@users.noreply.github.com,2021-04-17 22:50:55,torch/testing/_internal/common_methods_invocations.py,# TODO: backward uses in-place operations that vmap doesn't like
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: some signatures of median do support out
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: some signatures of nanmedian do support out
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: some signatures of var_mean do support out
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: complex inputs requiring grad error in forward
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: review with var_mean tests in test_autograd.py
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: some signatures of std_mean do support out
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: complex inputs requiring grad error in forward
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: fix along with var_mean autograd tests
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""max_elementwise_cuda"" not implemented for 'ComplexFloat'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""max_elementwise_cuda"" not implemented for 'ComplexFloat'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""min_elementwise_cuda"" not implemented for 'ComplexFloat'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""min_elementwise_cuda"" not implemented for 'ComplexFloat'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""bitwise_or_cuda"" not implemented for 'Half'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,"# TODO: FIXME: RuntimeError: ""bitwise_xor_cuda"" not implemented for 'Half'"
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: lcm doesn't support scalars
Mike Ruberry,mruberry@devfair044.h1.fair,2021-12-06 07:30:44,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: jiterator doesn't support non-tensor inputs
Nikita Vedeneev,nik@quansight.com,2021-11-16 07:25:37,torch/testing/_internal/common_methods_invocations.py,# TODO: add shape checks
Nikita Vedeneev,nik@quansight.com,2021-11-16 07:25:37,torch/testing/_internal/common_methods_invocations.py,# TODO: add shape checks
Nikita Vedeneev,nik@quansight.com,2021-11-16 07:25:37,torch/testing/_internal/common_methods_invocations.py,# TODO: investigate nondeterminism
Heitor Schueroff,heitorschueroff@fb.com,2021-04-27 07:34:33,torch/testing/_internal/common_methods_invocations.py,# TODO(@heitorschueroff) update SampleInput to handle such cases
kshitij12345,kshitijkalambarkar@gmail.com,2021-05-01 20:49:55,torch/testing/_internal/common_methods_invocations.py,# TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
Elias Ellison,eellison@devfair044.h1.fair,2021-09-07 18:19:14,torch/testing/_internal/common_methods_invocations.py,"assert_jit_shape_analysis=False,  # TODO: support index.Tensor()"
Mike Ruberry,mruberry@fb.com,2021-09-09 10:02:03,torch/testing/_internal/common_methods_invocations.py,# TODO: see https://github.com/pytorch/pytorch/issues/64709
Mike Ruberry,mruberry@fb.com,2021-09-09 10:02:03,torch/testing/_internal/common_methods_invocations.py,# TODO: see https://github.com/pytorch/pytorch/issues/64709
Mike Ruberry,mruberry@fb.com,2021-09-09 10:02:03,torch/testing/_internal/common_methods_invocations.py,# TODO: see https://github.com/pytorch/pytorch/issues/64709
Mike Ruberry,mruberry@fb.com,2021-09-09 10:02:03,torch/testing/_internal/common_methods_invocations.py,# TODO: see https://github.com/pytorch/pytorch/issues/64709
Nikita Shulga,nshulga@fb.com,2021-07-20 18:13:32,torch/testing/_internal/common_methods_invocations.py,"OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'"
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: complex inputs requiring grad error in forward
Mike Ruberry,mruberry@devfair044.maas,2021-06-17 06:33:48,torch/testing/_internal/common_methods_invocations.py,# TODO: FIXME: sigmoid fails on complex inputs that require grad
Natalia Gimelshein,ngimel@fb.com,2021-09-20 10:11:29,torch/testing/_internal/common_methods_invocations.py,# TODO(@heitorschueroff) std return float for complex types
Natalia Gimelshein,ngimel@fb.com,2021-09-20 10:11:29,torch/testing/_internal/common_methods_invocations.py,# TODO(@heitorschueroff) std return float for complex types
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: review porting these to make_tensor
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: move all tri/tril/triu testing to tensor creation op test suite and remove
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_methods_invocations.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_methods_invocations.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: move into common_utils.py or the test suite(s) that use this
Mike Ruberry,mruberry@devfair044.maas,2021-06-06 14:51:26,torch/testing/_internal/common_methods_invocations.py,# TODO: move into common_utils.py or the test suite(s) that use this
Thomas J. Fan,thomasjpfan@gmail.com,2021-09-24 13:08:44,torch/testing/_internal/common_modules.py,# TODO: Uncomment when negative weights is supported.
Mikayla Gawarecki,mikaylagawarecki@gmail.com,2021-12-29 14:50:25,torch/testing/_internal/common_modules.py,# TODO: test_non_contiguous_tensors doesn't handle case where output is not a singleton (such as
Mikayla Gawarecki,mikaylagawarecki@gmail.com,2021-12-29 14:50:25,torch/testing/_internal/common_modules.py,"# TODO: test_cpu_gpu_parity doesn't handle case where output is not a singleton, submit fix"
Adam Paszke,adam.paszke@gmail.com,2016-09-13 15:11:56,test/common_nn.py,# TODO: reference function
Richard Zou,zou3519@gmail.com,2021-01-22 15:28:02,torch/testing/_internal/common_nn.py,"# TODO(#50743): Figure out the error. ""RuntimeError: Unrecognized tensor type ID: Batched"""
Richard Zou,zou3519@gmail.com,2021-01-22 15:28:02,torch/testing/_internal/common_nn.py,# TODO(#50743): figure out the error
Thomas J. Fan,thomasjpfan@gmail.com,2021-08-29 23:31:42,torch/testing/_internal/common_nn.py,# TODO: This code can path can be removed if #61309 is resolved
kshitij12345,kshitijkalambarkar@gmail.com,2021-10-18 15:28:38,torch/testing/_internal/common_nn.py,# TODO : Fix these discrepancies
lixinyu,lixinyu@devgpu175.prn2.facebook.com,2020-09-28 22:03:16,torch/testing/_internal/common_nn.py,# TODO: compare structure (ensure analytic jacobian has correct shape)
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Adam Paszke,adam.paszke@gmail.com,2017-09-29 08:52:35,test/common_nn.py,# TODO: do this with in-memory files as soon as torch.save will support it
Gregory Chanan,gchanan@fb.com,2020-09-18 07:01:58,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Gregory Chanan,gchanan@fb.com,2020-09-18 07:01:58,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Vitaly Fedyunin,vitalyf@fb.com,2020-05-09 14:44:39,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Peter Bell,peterbell10@live.co.uk,2021-01-22 09:34:29,torch/testing/_internal/common_nn.py,# TODO: torch.complex32 when properly supported
Will Feng,willfeng@fb.com,2020-03-24 13:57:37,torch/testing/_internal/common_nn.py,# TODO: check that criterions don't ignore grad_output
Gregory Chanan,gchanan@fb.com,2020-09-10 08:15:45,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
Gregory Chanan,gchanan@fb.com,2020-09-10 08:15:45,torch/testing/_internal/common_nn.py,# TODO(#38095): Replace assertEqualIgnoreType. See issue #38095
James Reed,jamesreed@fb.com,2020-10-29 17:01:02,torch/testing/_internal/common_quantization.py,# TODO: make img_data a single example instead of a list
Supriya Rao,supriyar@fb.com,2020-05-06 22:32:45,torch/testing/_internal/common_quantized.py,# TODO: Update all quantization tests to use this decorator.
Rong Rong,rongr@fb.com,2020-09-28 16:26:42,torch/testing/_internal/common_utils.py,# TODO fix when https://github.com/python/mypy/issues/2427 is address
Aswin John Mathews,Aswin.Mathews@amd.com,2021-09-10 08:05:21,torch/testing/_internal/common_utils.py,# TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
Philip Meier,github.pmeier@posteo.de,2022-01-26 23:35:24,torch/testing/_internal/common_utils.py,# TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
Philip Meier,github.pmeier@posteo.de,2022-01-26 23:35:24,torch/testing/_internal/common_utils.py,"# TODO: As discussed in https://github.com/pytorch/pytorch/issues/68590#issuecomment-975333883,"
Edward Yang,ezyang@fb.com,2021-03-14 20:36:59,torch/testing/_internal/common_utils.py,# TODO: sure looks like we unconditionally initialize the context here
Mike Ruberry,mruberry@devfair044.maas,2020-06-03 15:25:06,torch/testing/_internal/common_utils.py,"# TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)"
Philip Meier,github.pmeier@posteo.de,2022-01-26 23:35:24,torch/testing/_internal/common_utils.py,# TODO: default this to True
Edward Z. Yang,ezyang@fb.com,2017-09-18 18:55:33,test/common.py,# TODO: Support context manager interface
Mike Ruberry,mruberry@fb.com,2021-10-29 09:52:24,torch/testing/_internal/common_utils.py,# TODO: consider more complicated noncontiguity schemes
Mike Ruberry,mruberry@devfair044.maas,2021-04-11 20:37:46,torch/testing/_internal/common_utils.py,# TODO: remove this (prefer make_symmetric_matrices below)
Mike Ruberry,mruberry@devfair044.maas,2021-04-11 20:37:46,torch/testing/_internal/common_utils.py,# TODO: remove this (prefer make_symmetric_pd_matrices below)
Richard Zou,zou3519@gmail.com,2021-11-30 07:33:58,torch/testing/_internal/composite_compliance.py,# TODO: move this into library proper
Rohan Varma,rvarm1@fb.com,2021-05-05 10:12:20,torch/testing/_internal/distributed/distributed_test.py,"# TODO: now that nccl send/recv is supported, there does not seem to"
Rohan Varma,rvarm1@fb.com,2021-04-25 19:38:58,torch/testing/_internal/distributed/distributed_test.py,# TODO: move this test to use torch.profiler once kineto issues are
Rohan Varma,rvarm1@fb.com,2020-09-08 23:08:55,torch/testing/_internal/distributed/distributed_test.py,# TODO: Instead we should probably go through _rank_not_in_group
Rohan Varma,rvarm1@fb.com,2020-09-08 23:08:55,torch/testing/_internal/distributed/distributed_test.py,# TODO: NCCL backend does not work correctly for bitwise reduction ops
Rohan Varma,rvarm1@fb.com,2021-08-09 22:27:49,torch/testing/_internal/distributed/distributed_test.py,# TODO: enable this for general training use cases:
Rohan Varma,rvarm1@fb.com,2021-04-04 21:36:55,torch/testing/_internal/distributed/distributed_test.py,# TODO(#54879): Provide ability to wait and report all failed ranks
Yi Wang,wayi@fb.com,2021-04-26 20:00:57,torch/testing/_internal/distributed/nn/api/remote_module_test.py,"# TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be ""cuda:0""."
Yi Wang,wayi@fb.com,2021-04-26 20:00:57,torch/testing/_internal/distributed/nn/api/remote_module_test.py,"# TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be ""cuda:0""."
Yi Wang,wayi@fb.com,2021-04-26 20:00:57,torch/testing/_internal/distributed/nn/api/remote_module_test.py,"# TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be ""cuda:0""."
Yanli Zhao,yanlizhao@fb.com,2020-02-24 11:14:00,torch/testing/_internal/distributed/rpc/dist_autograd_test.py,"# TODO, need more investigation"
Shihao Xu,shihaoxu@fb.com,2020-02-24 21:38:07,torch/testing/_internal/distributed/rpc/jit/rpc_test.py,"# TODO, need more investigation"
Rohan Varma,rvarm1@fb.com,2020-04-20 12:35:39,torch/testing/_internal/distributed/rpc/jit/rpc_test.py,# TODO: Can't get a reliable time for this profiling event since
Shen Li,shenli@fb.com,2020-06-02 23:19:21,torch/testing/_internal/distributed/rpc/rpc_test.py,# TODO: use torch.futures.collect_all
Rohan Varma,rvarm1@fb.com,2020-12-01 17:37:04,torch/testing/_internal/distributed/rpc/rpc_test.py,"# TODO: with TCP init, rank 0 raises Address already in use because"
Rohan Varma,rvarm1@fb.com,2020-04-22 12:55:39,torch/testing/_internal/distributed/rpc/rpc_test.py,# TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
Zafar Takhirov,zaf@fb.com,2019-07-17 10:12:38,test/hypothesis_utils.py,# TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
Mike Ruberry,mruberry@devfair044.maas,2020-11-28 20:09:52,torch/testing/_internal/jit_metaprogramming_utils.py,# TODO: include files like this should not set the default dtype
Elias Ellison,eellison@fb.com,2020-03-23 11:53:18,torch/testing/_internal/jit_metaprogramming_utils.py,# flaky test - TODO fix
Elias Ellison,eellison@fb.com,2020-03-23 11:53:18,torch/testing/_internal/jit_metaprogramming_utils.py,# TODO: delete this list once we make all nn_tests work
davidriazati,davidriazati@fb.com,2019-06-06 15:46:44,test/jit_utils.py,"# TODO: check gradients for parameters, not just inputs"
Michael Suo,suo@fb.com,2019-08-19 18:41:08,test/jit_utils.py,# TODO(suo) remove
Nikita Shulga,nshulga@fb.com,2021-01-26 12:41:09,torch/testing/_internal/jit_utils.py,# TODO: Remove me once https://bugs.python.org/issue42666 is resolved
Brian Hirsh,hirsheybar@fb.com,2021-11-09 14:29:55,torch/testing/_internal/logging_tensor.py,# TODO: move this into library proper
Brian Hirsh,hirsheybar@fb.com,2021-11-09 14:29:55,torch/testing/_internal/logging_tensor.py,# TODO: TensorBase should work
Brian Hirsh,hirsheybar@fb.com,2021-11-09 14:29:55,torch/testing/_internal/logging_tensor.py,# TODO: clone storage aliasing
Richard Zou,zou3519@gmail.com,2021-09-16 09:00:34,torch/utils/_python_dispatch.py,# TODO: Limitations and things about enable_python_mode we should fix before exposing it:
David Reiss,dreiss@fb.com,2020-04-08 13:06:51,torch/utils/bundled_inputs.py,# TODO: Should we do this even for non-contiguous tensors?
David Reiss,dreiss@fb.com,2020-04-08 13:06:51,torch/utils/bundled_inputs.py,# TODO: Provide more useful diagnostics.
Rohan Varma,rvarm1@fb.com,2021-12-07 16:26:36,torch/utils/checkpoint.py,"# TODO(varal7): Instead of returning indices, we can return things metadata (such as"
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-07-21 21:37:09,torch/utils/data/__init__.py,"# TODO(VitalyFedyunin): Rearranging this imports leads to crash,"
Erjia Guan,erjia@fb.com,2021-03-15 14:40:55,torch/utils/data/decorator.py,# TODO: Lambda for picking
Erjia Guan,erjia@fb.com,2021-04-02 15:19:06,torch/utils/data/decorator.py,# TODO:
Erjia Guan,erjia@fb.com,2021-04-02 15:19:06,torch/utils/data/_typing.py,# TODO: Use TypeAlias when Python 3.6 is deprecated
Erjia Guan,erjia@fb.com,2021-04-02 15:19:06,torch/utils/data/_typing.py,"# TODO: When PyTorch drops the support for Python 3.6, it can be converted"
Erjia Guan,erjia@fb.com,2021-04-02 15:19:06,torch/utils/data/_typing.py,# TODO:
Erjia Guan,erjia@fb.com,2021-04-27 08:12:52,torch/utils/data/_utils/worker.py,# TODO: Implement `SeedSequence` like object for `torch.random`
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/protocol.py,except Exception as e:  # TODO: Catch only timeout exceptions
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/protocol.py,# TODO: Validate supported requests
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/protocol.py,except Exception as e:  # TODO: Catch only timeout exceptions
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/protocol.py,except Exception as e:  # TODO: Catch only timeout exceptions
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/protocol.py,# TODO(VitalyFedyunin): Add possible response types validation here
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/queue.py,# TODO(VitalyFedyunin): Add support of block and timeout arguments
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/queue.py,# TODO(VitalyFedyunin): Add support of block and timeout arguments
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-08-30 07:54:11,torch/utils/data/communication/queue.py,# TODO(VitalyFedyunin): Figure out what to do if nothing in the queue
Tongzhou Wang,tongzhou.wang.1994@gmail.com,2019-06-20 20:03:30,torch/utils/data/dataloader.py,# TODO: add limited pickling support for sharing an iterator
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-09-13 18:48:48,torch/utils/data/datapipes/dataframe/dataframes.py,# TODO(VitalyFedyunin): Add error when two different traces get combined
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-09-13 18:48:48,torch/utils/data/datapipes/dataframe/dataframes.py,#  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2022-01-25 18:42:02,torch/utils/data/datapipes/dataframe/dataframes.py,"# TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures"
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2022-01-25 18:42:02,torch/utils/data/datapipes/dataframe/dataframes.py,# TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-09-13 18:48:48,torch/utils/data/datapipes/dataframe/datapipes.py,except Exception:  # TODO(VitalyFedyunin): Replace with better iterable exception
Erjia Guan,erjia@fb.com,2021-04-28 13:11:53,torch/utils/data/datapipes/iter/loadfilesfromdisk.py,"# TODO: enforce typing for each instance based on mode, otherwise"
lixinyu,lixinyu@devgpu175.prn2.facebook.com,2021-02-09 03:28:04,torch/utils/data/datapipes/utils/decoder.py,"# TODO: xinyu, figure out why Nvidia do this?"
Kevin Tse,ktse@fb.com,2021-12-10 12:03:14,torch/utils/data/gen_pyi.py,TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
Kevin Tse,ktse@fb.com,2021-11-08 14:35:51,torch/utils/data/gen_pyi.py,main()  # TODO: Run this script automatically within the build and CI process
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-07-12 10:27:42,torch/utils/data/graph.py,# TODO(VitalyFedyunin): Make sure it works without dill module installed
Vitaly Fedyunin,vitaly.fedyunin@gmail.com,2021-12-14 07:33:12,torch/utils/data/graph.py,pass  # TODO(VitalyFedyunin): We need to tight this requirement after migrating from old DataLoader
Emilio Castillo,ecastill@preferred.jp,2021-09-12 19:45:57,torch/utils/dlpack.py,# TODO: add a typing.Protocol to be able to tell Mypy that only objects with
Your Name,bai@in.tum.de,2019-10-07 17:22:33,torch/utils/hipify/cuda_to_hip_mappings.py,# TODO: Undo this special-case; see the header for motivation behind this
iotamudelta,dieterich@ogolem.org,2018-08-06 14:48:45,tools/amd_build/pyHIPIFY/hipify-python.py,TODO:
Junjie Bai,jbai@fb.com,2019-05-23 12:46:08,torch/utils/mkldnn.py,# TODO: Remove this once ScriptModule supports registering None buffer
Junjie Bai,jbai@fb.com,2019-05-23 12:46:08,torch/utils/mkldnn.py,# TODO: Remove this once ScriptModule supports registering None buffer
David Reiss,dreiss@fb.com,2021-04-28 07:31:54,torch/utils/model_dump/__init__.py,- Fix various TODO comments in this file and the JS.
David Reiss,dreiss@fb.com,2021-06-04 19:41:19,torch/utils/model_dump/__init__.py,# TODO: Undo at least that second hack.  We should support string states.
David Reiss,dreiss@fb.com,2021-04-28 07:31:54,torch/utils/model_dump/__init__.py,"# TODO: Handle this case better.  TorchScript ranges are in bytes,"
David Reiss,dreiss@fb.com,2021-04-28 07:31:54,torch/utils/model_dump/__init__.py,# TODO: handle errors here and just ignore the file?
Tzu-Wei Huang,huang.dexter@gmail.com,2019-04-25 21:22:34,torch/utils/tensorboard/_pytorch_graph.py,# TODO; Specify a __slots__ for this class or potentially
Tzu-Wei Huang,huang.dexter@gmail.com,2019-04-25 21:22:34,torch/utils/tensorboard/_pytorch_graph.py,# TODO: See if we can remove this in the future
Tzu-Wei Huang,huang.dexter@gmail.com,2019-05-08 14:03:04,torch/utils/tensorboard/_pytorch_graph.py,# TODO: compute correct memory usage and CPU time once
Lara Haidar,haidar.lara@gmail.com,2020-03-29 23:12:32,torch/utils/tensorboard/_pytorch_graph.py,"with torch.onnx.select_model_mode_for_export(model, torch.onnx.TrainingMode.EVAL):  # TODO: move outside of torch.onnx?"
Tzu-Wei Huang,huang.dexter@gmail.com,2019-04-25 21:22:34,torch/utils/tensorboard/_pytorch_graph.py,# TODO: See if we can extract GPU vs CPU information from the PyTorch model
Tzu-Wei Huang,huang.dexter@gmail.com,2019-08-26 10:38:30,torch/utils/tensorboard/summary.py,# TODO: expose other parameters in the future.
Tzu-Wei Huang,huang.dexter@gmail.com,2019-04-25 21:22:34,torch/utils/tensorboard/writer.py,# TODO: See if we can remove this in the future if we are
